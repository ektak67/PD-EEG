{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wlRWK41WVBww"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from keras.layers import Lambda\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Conv2D, Conv3D, AveragePooling2D, AveragePooling3D, MaxPooling2D\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Flatten, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.layers import TimeDistributed, LSTM, Bidirectional, ConvLSTM2D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dx6VSZc49Mpz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (7412, 5, 32, 32, 3)\n",
      "Number of classes: 2\n",
      "Labels shape: (7412,)\n"
     ]
    }
   ],
   "source": [
    "dataPath = '../data/spectral_feat_tensor_full_with_full_labels_images_3dcnn_norm.mat'\n",
    "savePath = '../Results/CNN_LSTM/'\n",
    "\n",
    "architectures = ['Plain_LSTM', '2D-CNN_LSTM_Bashivan', '2D-CNN_LSTM_Our', 'Conv_LSTM', 'BiLSTM'] \n",
    "\n",
    "arch = 'Conv_LSTM'\n",
    "\n",
    "experiment = 'HVLV' # HVLV or HALA or Multi\n",
    "\n",
    "data = 'NC' # FUll or PD or NC\n",
    "\n",
    "filename = savePath+arch+\"_\"+experiment+\"_2L\"+\"_\"+data+\".mat\"\n",
    "\n",
    "if experiment == 'HVLV':\n",
    "    title = 'HV vs LV Classification '+'('+data+')'\n",
    "    conf_mat = np.zeros((2,2))\n",
    "    conf_mat_labels = [0,1]\n",
    "    plot_labels = ['LV', 'HV']\n",
    "    \n",
    "elif experiment == 'HALA':\n",
    "    title = 'HA vs LA Classification '+'('+data+')'\n",
    "    conf_mat = np.zeros((2,2))\n",
    "    conf_mat_labels = [0,1]\n",
    "    plot_labels = ['LA', 'HA']\n",
    "    \n",
    "elif experiment == 'Multi':\n",
    "    title = 'Categorical Emotion Classification '+'('+data+')'\n",
    "    conf_mat = np.zeros((6,6))\n",
    "    conf_mat_labels = [1, 2, 3, 4, 5, 0]\n",
    "    plot_labels = ['Sad', 'Happy', 'Fear', 'Disgust', 'Surprise', 'Anger']\n",
    "    \n",
    "else:\n",
    "    raise ValueError('Expecting HVLV, HALA, Multi only.')\n",
    "\n",
    "nb_filters = [16, 32, 32, 64, 128]\n",
    "#nb_filters = [64, 64]\n",
    "kernel_size = 3\n",
    "pool_size = 2\n",
    "stride_size = 2\n",
    "padding = 'same'\n",
    "weight_decay = 0.000001\n",
    "dense_layer_neuron_num = 512\n",
    "optimizer='Adam'\n",
    "init_mode = 'he_normal'\n",
    "activation='relu'\n",
    "learn_rate = 0.0001\n",
    "momentum = 0.8\n",
    "dropout_rate = 0.5\n",
    "num_units = 512\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "foldNum = 10\n",
    "\n",
    "'''\n",
    "with open(dataPath, 'rb') as pkl:\n",
    "    data = pickle.load(pkl)\n",
    "'''\n",
    "\n",
    "matContent = sio.loadmat(dataPath)\n",
    "features = matContent[data.lower()+'_feat_img'] #full_feat_img or pd_feat_img or nc_feat_img\n",
    "labels = np.squeeze(matContent[data.lower()+'_'+experiment.lower()+'_'+'labels']) # eg pd_hvlv_labels\n",
    " \n",
    "features = np.swapaxes(features,2,4)\n",
    "features = np.swapaxes(features,2,3)\n",
    "\n",
    "if experiment == 'Multi':\n",
    "    labels[labels == 6]=0\n",
    "\n",
    "#labels[labels < 0] = 0\n",
    "#labels = labels.astype(int)\n",
    "\n",
    "# randomise the sample sequence\n",
    "rand_order = np.arange(features.shape[0])\n",
    "np.random.shuffle(rand_order)\n",
    "features = features[rand_order,]\n",
    "labels = np.squeeze(labels[rand_order,])\n",
    "class_num = np.size(np.unique(labels))\n",
    "labels_categorical = np_utils.to_categorical(labels)\n",
    "del matContent\n",
    "#del data\n",
    "\n",
    "print('Features shape:',features.shape)\n",
    "print('Number of classes:',class_num)\n",
    "print('Labels shape:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plain_lstm_model(optimizer, activation, num_units, dropout_rate, learn_rate):\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(num_units, activation=activation, return_sequences=True, \n",
    "                   input_shape=(features.shape[1],features.shape[2])))\n",
    "    model.add(LSTM(num_units, activation=activation, return_sequences=True))\n",
    "    model.add(LSTM(num_units, activation=activation, return_sequences=False))\n",
    "    model.add(Dense(dense_layer_neuron_num, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(class_num, activation='softmax'))\n",
    "    #model.add(Activation('softmax'))\n",
    "    if optimizer == 'Adagrad':\n",
    "        opt = Adagrad(learning_rate=learn_rate)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    elif optimizer == 'Adam':\n",
    "        opt = Adam(learning_rate=learn_rate)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    elif optimizer == 'RMSprop':\n",
    "        opt = RMSprop(learning_rate=learn_rate, epsilon=1e-07)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn2d_lstm_model_bashivan(optimizer, activation, kernel_size, padding, init_mode,\n",
    "                              pool_size, stride_size, num_units, dense_layer_neuron_num,\n",
    "                              nb_filters, class_num, dropout_rate, learn_rate):\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv2D(filters=nb_filters[0], kernel_size=kernel_size, padding=padding, \n",
    "                                     activation=activation, trainable=True), \n",
    "                              input_shape=(features.shape[1], features.shape[2], \n",
    "                                           features.shape[3], features.shape[4])))\n",
    "    model.add(TimeDistributed(Conv2D(filters=nb_filters[1], kernel_size=kernel_size,\n",
    "                                     padding=padding, activation=activation,\n",
    "                                     kernel_initializer=init_mode, trainable=True)))  \n",
    "    model.add(TimeDistributed(Conv2D(filters=nb_filters[2], kernel_size=kernel_size,\n",
    "                                     padding=padding, activation=activation,\n",
    "                                     kernel_initializer=init_mode, trainable=True)))\n",
    "    model.add(TimeDistributed(Conv2D(filters=nb_filters[3], kernel_size=kernel_size,\n",
    "                                     padding=padding, activation=activation,\n",
    "                                     kernel_initializer=init_mode, trainable=True)))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=pool_size, strides=stride_size, padding=padding)))\n",
    "    model.add(TimeDistributed(Conv2D(filters=nb_filters[4], kernel_size=kernel_size,\n",
    "                                     padding=padding, activation=activation,\n",
    "                                     kernel_initializer=init_mode, trainable=True)))\n",
    "    model.add(TimeDistributed(Conv2D(filters=nb_filters[5], kernel_size=kernel_size,\n",
    "                                     padding=padding, activation=activation,\n",
    "                                     kernel_initializer=init_mode, trainable=True)))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=pool_size, strides=stride_size, padding=padding)))\n",
    "    model.add(TimeDistributed(Conv2D(filters=nb_filters[6], kernel_size=kernel_size,\n",
    "                                     padding=padding, activation=activation,\n",
    "                                     kernel_initializer=init_mode, trainable=True)))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=pool_size, strides=stride_size, padding=padding)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(units=num_units))\n",
    "    #model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(dense_layer_neuron_num))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(class_num, activation='softmax'))\n",
    "    if optimizer == 'SGD':\n",
    "        opt = SGD(learning_rate=learn_rate / 10 ** epochs, momentum = momentum, decay = weight_decay, nesterov = True)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    elif optimizer == 'Adam':\n",
    "        opt = Adam(learning_rate=learn_rate)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    elif optimizer == 'RMSprop':\n",
    "        opt = RMSprop(learning_rate=learn_rate, epsilon=1e-07)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn2d_lstm_model_our(optimizer, activation, kernel_size, padding, init_mode,\n",
    "                         pool_size, stride_size, num_units, dense_layer_neuron_num,\n",
    "                         nb_filters, class_num, dropout_rate, learn_rate):\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv2D(filters=nb_filters[0], kernel_size=kernel_size, padding=padding, \n",
    "                                     activation=activation, trainable=True), \n",
    "                              input_shape=(features.shape[1], features.shape[2], \n",
    "                                           features.shape[3], features.shape[4])))\n",
    "    model.add(TimeDistributed(AveragePooling3D(pool_size=pool_size, strides=stride_size, padding=padding)))\n",
    "    model.add(TimeDistributed(Conv2D(filters=nb_filters[1], kernel_size=kernel_size,\n",
    "                                     padding=padding, activation=activation, \n",
    "                                     kernel_initializer=init_mode, trainable=True)))\n",
    "    model.add(TimeDistributed(AveragePooling3D(pool_size=pool_size, strides=stride_size, padding=padding)))\n",
    "    model.add(TimeDistributed(Conv2D(filters=nb_filters[2], kernel_size=kernel_size, \n",
    "                                     padding=padding, activation=activation,\n",
    "                                     kernel_initializer=init_mode, trainable=True)))\n",
    "    model.add(TimeDistributed(AveragePooling3D(pool_size=pool_size, strides=stride_size, padding=padding)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(units=num_units))\n",
    "    #model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(dense_layer_neuron_num))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(class_num, activation='softmax'))\n",
    "    if optimizer == 'SGD':\n",
    "        opt = SGD(learning_rate=learn_rate / 10 ** epochs, momentum = momentum, decay = weight_decay, nesterov = True)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    elif optimizer == 'Adam':\n",
    "        opt = Adam(learning_rate=learn_rate)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    elif optimizer == 'RMSprop':\n",
    "        opt = RMSprop(learning_rate=learn_rate, epsilon=1e-07)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_lstm_model(optimizer, activation, kernel_size, padding, init_mode,\n",
    "                    pool_size, stride_size, num_units, dense_layer_neuron_num,\n",
    "                    nb_filters, class_num, dropout_rate, learn_rate):\n",
    "    model = Sequential()\n",
    "    model.add(ConvLSTM2D(filters=nb_filters[0], kernel_size=kernel_size, padding=padding, activation=activation, \n",
    "                         kernel_initializer=init_mode, return_sequences=True,\n",
    "                         input_shape=(features.shape[1], features.shape[2], features.shape[3], features.shape[4])))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ConvLSTM2D(filters=nb_filters[1], kernel_size=kernel_size, padding=padding, activation=activation, \n",
    "                         kernel_initializer=init_mode, return_sequences=True))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(ConvLSTM2D(filters=nb_filters[2], kernel_size=kernel_size, padding=padding, activation=activation, \n",
    "    #                     kernel_initializer=init_mode, return_sequences=False))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(dense_layer_neuron_num, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(class_num, activation='softmax'))\n",
    "    if optimizer == 'Adam':\n",
    "        opt = Adam(learning_rate=learn_rate)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    elif optimizer == 'RMSprop':\n",
    "        opt = RMSprop(learning_rate=learn_rate, epsilon=1e-07)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilstm_model(optimizer, activation, kernel_size, padding, init_mode,\n",
    "                 pool_size, stride_size, num_units, dense_layer_neuron_num,\n",
    "                 nb_filters, class_num, dropout_rate, learn_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(num_units, return_sequences=True, activation=activation),\n",
    "                            input_shape=(features.shape[1],features.shape[2])))\n",
    "    model.add(Bidirectional(LSTM(num_units)))\n",
    "    #model.add(Flatten())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(dense_layer_neuron_num, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(class_num, activation='softmax'))\n",
    "    if optimizer == 'Adam':\n",
    "        opt = Adam(learning_rate=learn_rate)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    elif optimizer == 'RMSprop':\n",
    "        opt = RMSprop(learning_rate=learn_rate, epsilon=1e-07)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "o9AZLvueTLGz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d (ConvLSTM2D)    (None, 5, 32, 32, 16)     11008     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 5, 32, 32, 16)     64        \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, 5, 32, 32, 32)     55424     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 5, 32, 32, 32)     128       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 163840)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 163840)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               83886592  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 83,954,242\n",
      "Trainable params: 83,954,146\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "188/188 - 41s - loss: 1.0671 - accuracy: 0.6520 - val_loss: 0.5793 - val_accuracy: 0.7016\n",
      "Epoch 2/30\n",
      "188/188 - 11s - loss: 0.5733 - accuracy: 0.7141 - val_loss: 0.5087 - val_accuracy: 0.7436\n",
      "Epoch 3/30\n",
      "188/188 - 11s - loss: 0.5362 - accuracy: 0.7353 - val_loss: 0.4848 - val_accuracy: 0.7496\n",
      "Epoch 4/30\n",
      "188/188 - 11s - loss: 0.5006 - accuracy: 0.7605 - val_loss: 0.4973 - val_accuracy: 0.7556\n",
      "Epoch 5/30\n",
      "188/188 - 11s - loss: 0.4626 - accuracy: 0.7731 - val_loss: 0.4553 - val_accuracy: 0.7676\n",
      "Epoch 6/30\n",
      "188/188 - 11s - loss: 0.4500 - accuracy: 0.7826 - val_loss: 0.4588 - val_accuracy: 0.7676\n",
      "Epoch 7/30\n",
      "188/188 - 11s - loss: 0.4201 - accuracy: 0.7988 - val_loss: 0.4751 - val_accuracy: 0.7841\n",
      "Epoch 8/30\n",
      "188/188 - 11s - loss: 0.4097 - accuracy: 0.8088 - val_loss: 0.4464 - val_accuracy: 0.7826\n",
      "Epoch 9/30\n",
      "188/188 - 11s - loss: 0.3746 - accuracy: 0.8224 - val_loss: 0.4407 - val_accuracy: 0.7901\n",
      "Epoch 10/30\n",
      "188/188 - 11s - loss: 0.3629 - accuracy: 0.8299 - val_loss: 0.4248 - val_accuracy: 0.8096\n",
      "Epoch 11/30\n",
      "188/188 - 11s - loss: 0.3414 - accuracy: 0.8344 - val_loss: 0.4213 - val_accuracy: 0.7961\n",
      "Epoch 12/30\n",
      "188/188 - 11s - loss: 0.3130 - accuracy: 0.8486 - val_loss: 0.4321 - val_accuracy: 0.8081\n",
      "Epoch 13/30\n",
      "188/188 - 11s - loss: 0.3038 - accuracy: 0.8562 - val_loss: 0.4529 - val_accuracy: 0.7946\n",
      "Epoch 14/30\n",
      "188/188 - 11s - loss: 0.3016 - accuracy: 0.8581 - val_loss: 0.4466 - val_accuracy: 0.7961\n",
      "Epoch 15/30\n",
      "188/188 - 11s - loss: 0.2890 - accuracy: 0.8612 - val_loss: 0.4487 - val_accuracy: 0.8201\n",
      "Epoch 16/30\n",
      "188/188 - 11s - loss: 0.2808 - accuracy: 0.8676 - val_loss: 0.4385 - val_accuracy: 0.8141\n",
      "Epoch 17/30\n",
      "188/188 - 11s - loss: 0.2630 - accuracy: 0.8771 - val_loss: 0.4531 - val_accuracy: 0.8201\n",
      "Epoch 18/30\n",
      "188/188 - 11s - loss: 0.2474 - accuracy: 0.8812 - val_loss: 0.4232 - val_accuracy: 0.8246\n",
      "Epoch 19/30\n",
      "188/188 - 11s - loss: 0.2357 - accuracy: 0.8937 - val_loss: 0.4553 - val_accuracy: 0.8351\n",
      "Epoch 20/30\n",
      "188/188 - 11s - loss: 0.2339 - accuracy: 0.8867 - val_loss: 0.4947 - val_accuracy: 0.8126\n",
      "Epoch 21/30\n",
      "188/188 - 11s - loss: 0.2341 - accuracy: 0.8916 - val_loss: 0.4781 - val_accuracy: 0.8171\n",
      "Epoch 22/30\n",
      "188/188 - 11s - loss: 0.2143 - accuracy: 0.8972 - val_loss: 0.4372 - val_accuracy: 0.8216\n",
      "Epoch 23/30\n",
      "188/188 - 11s - loss: 0.2077 - accuracy: 0.8977 - val_loss: 0.4428 - val_accuracy: 0.8411\n",
      "Epoch 24/30\n",
      "188/188 - 11s - loss: 0.1974 - accuracy: 0.9049 - val_loss: 0.4303 - val_accuracy: 0.8321\n",
      "Epoch 25/30\n",
      "188/188 - 11s - loss: 0.2022 - accuracy: 0.9054 - val_loss: 0.4207 - val_accuracy: 0.8321\n",
      "Epoch 26/30\n",
      "188/188 - 11s - loss: 0.1885 - accuracy: 0.9094 - val_loss: 0.4009 - val_accuracy: 0.8411\n",
      "Epoch 27/30\n",
      "188/188 - 11s - loss: 0.1810 - accuracy: 0.9119 - val_loss: 0.4573 - val_accuracy: 0.8336\n",
      "Epoch 28/30\n",
      "188/188 - 11s - loss: 0.1837 - accuracy: 0.9109 - val_loss: 0.4930 - val_accuracy: 0.8291\n",
      "Epoch 29/30\n",
      "188/188 - 11s - loss: 0.1772 - accuracy: 0.9104 - val_loss: 0.5052 - val_accuracy: 0.8231\n",
      "Epoch 30/30\n",
      "188/188 - 11s - loss: 0.1687 - accuracy: 0.9162 - val_loss: 0.5075 - val_accuracy: 0.8261\n",
      "WARNING:tensorflow:From <ipython-input-8-6bd4d4e94c5f>:52: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "HVLV_CNN_LSTM: Fold 1 : f1_macroscore: 0.8118\n",
      "HVLV_CNN_LSTM: Fold 1 : f1_weightedscore: 0.8352\n",
      "HVLV_CNN_LSTM: Fold 1 : acc: 0.8410\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d (ConvLSTM2D)    (None, 5, 32, 32, 16)     11008     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 5, 32, 32, 16)     64        \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, 5, 32, 32, 32)     55424     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 5, 32, 32, 32)     128       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 163840)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 163840)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               83886592  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 83,954,242\n",
      "Trainable params: 83,954,146\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "188/188 - 11s - loss: 1.0609 - accuracy: 0.6457 - val_loss: 0.5947 - val_accuracy: 0.7091\n",
      "Epoch 2/30\n",
      "188/188 - 11s - loss: 0.5913 - accuracy: 0.7106 - val_loss: 0.5599 - val_accuracy: 0.7166\n",
      "Epoch 3/30\n",
      "188/188 - 11s - loss: 0.5416 - accuracy: 0.7395 - val_loss: 0.5242 - val_accuracy: 0.7301\n",
      "Epoch 4/30\n",
      "188/188 - 11s - loss: 0.5068 - accuracy: 0.7576 - val_loss: 0.5023 - val_accuracy: 0.7586\n",
      "Epoch 5/30\n",
      "188/188 - 11s - loss: 0.4815 - accuracy: 0.7668 - val_loss: 0.5207 - val_accuracy: 0.7316\n",
      "Epoch 6/30\n",
      "188/188 - 11s - loss: 0.4575 - accuracy: 0.7814 - val_loss: 0.4777 - val_accuracy: 0.7766\n",
      "Epoch 7/30\n",
      "188/188 - 11s - loss: 0.4311 - accuracy: 0.7898 - val_loss: 0.4656 - val_accuracy: 0.7871\n",
      "Epoch 8/30\n",
      "188/188 - 11s - loss: 0.4146 - accuracy: 0.8064 - val_loss: 0.4552 - val_accuracy: 0.7931\n",
      "Epoch 9/30\n",
      "188/188 - 11s - loss: 0.3844 - accuracy: 0.8189 - val_loss: 0.4635 - val_accuracy: 0.7706\n",
      "Epoch 10/30\n",
      "188/188 - 11s - loss: 0.3773 - accuracy: 0.8219 - val_loss: 0.4787 - val_accuracy: 0.7871\n",
      "Epoch 11/30\n",
      "188/188 - 11s - loss: 0.3513 - accuracy: 0.8333 - val_loss: 0.4496 - val_accuracy: 0.7991\n",
      "Epoch 12/30\n",
      "188/188 - 11s - loss: 0.3411 - accuracy: 0.8402 - val_loss: 0.4787 - val_accuracy: 0.7856\n",
      "Epoch 13/30\n",
      "188/188 - 11s - loss: 0.3273 - accuracy: 0.8519 - val_loss: 0.4284 - val_accuracy: 0.8081\n",
      "Epoch 14/30\n",
      "188/188 - 11s - loss: 0.3199 - accuracy: 0.8484 - val_loss: 0.4659 - val_accuracy: 0.7916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "188/188 - 11s - loss: 0.3061 - accuracy: 0.8599 - val_loss: 0.4426 - val_accuracy: 0.8036\n",
      "Epoch 16/30\n",
      "188/188 - 11s - loss: 0.3058 - accuracy: 0.8614 - val_loss: 0.4826 - val_accuracy: 0.8006\n",
      "Epoch 17/30\n",
      "188/188 - 11s - loss: 0.2836 - accuracy: 0.8697 - val_loss: 0.4627 - val_accuracy: 0.8156\n",
      "Epoch 18/30\n",
      "188/188 - 11s - loss: 0.2593 - accuracy: 0.8794 - val_loss: 0.4537 - val_accuracy: 0.7916\n",
      "Epoch 19/30\n",
      "188/188 - 11s - loss: 0.2574 - accuracy: 0.8789 - val_loss: 0.4667 - val_accuracy: 0.8216\n",
      "Epoch 20/30\n",
      "188/188 - 11s - loss: 0.2448 - accuracy: 0.8907 - val_loss: 0.5165 - val_accuracy: 0.8051\n",
      "Epoch 21/30\n",
      "188/188 - 11s - loss: 0.2524 - accuracy: 0.8847 - val_loss: 0.4749 - val_accuracy: 0.8216\n",
      "Epoch 22/30\n",
      "188/188 - 11s - loss: 0.2298 - accuracy: 0.8962 - val_loss: 0.5000 - val_accuracy: 0.8096\n",
      "Epoch 23/30\n",
      "188/188 - 11s - loss: 0.2300 - accuracy: 0.8962 - val_loss: 0.4673 - val_accuracy: 0.8216\n",
      "Epoch 24/30\n",
      "188/188 - 11s - loss: 0.2186 - accuracy: 0.9000 - val_loss: 0.4555 - val_accuracy: 0.8411\n",
      "Epoch 25/30\n",
      "188/188 - 11s - loss: 0.2139 - accuracy: 0.8992 - val_loss: 0.4891 - val_accuracy: 0.8276\n",
      "Epoch 26/30\n",
      "188/188 - 11s - loss: 0.2083 - accuracy: 0.9074 - val_loss: 0.4524 - val_accuracy: 0.8156\n",
      "Epoch 27/30\n",
      "188/188 - 11s - loss: 0.1993 - accuracy: 0.9074 - val_loss: 0.4552 - val_accuracy: 0.8396\n",
      "Epoch 28/30\n",
      "188/188 - 11s - loss: 0.1893 - accuracy: 0.9142 - val_loss: 0.4563 - val_accuracy: 0.8456\n",
      "Epoch 29/30\n",
      "188/188 - 11s - loss: 0.1886 - accuracy: 0.9159 - val_loss: 0.5310 - val_accuracy: 0.8231\n",
      "Epoch 30/30\n",
      "188/188 - 11s - loss: 0.1895 - accuracy: 0.9199 - val_loss: 0.5212 - val_accuracy: 0.8246\n",
      "HVLV_CNN_LSTM: Fold 2 : f1_macroscore: 0.8038\n",
      "HVLV_CNN_LSTM: Fold 2 : f1_weightedscore: 0.8257\n",
      "HVLV_CNN_LSTM: Fold 2 : acc: 0.8288\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d (ConvLSTM2D)    (None, 5, 32, 32, 16)     11008     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 5, 32, 32, 16)     64        \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, 5, 32, 32, 32)     55424     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 5, 32, 32, 32)     128       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 163840)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 163840)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               83886592  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 83,954,242\n",
      "Trainable params: 83,954,146\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "188/188 - 21s - loss: 0.9901 - accuracy: 0.6567 - val_loss: 0.5983 - val_accuracy: 0.7290\n",
      "Epoch 2/30\n",
      "188/188 - 11s - loss: 0.5585 - accuracy: 0.7208 - val_loss: 0.5247 - val_accuracy: 0.7410\n",
      "Epoch 3/30\n",
      "188/188 - 11s - loss: 0.5109 - accuracy: 0.7501 - val_loss: 0.4591 - val_accuracy: 0.7725\n",
      "Epoch 4/30\n",
      "188/188 - 11s - loss: 0.4754 - accuracy: 0.7663 - val_loss: 0.4660 - val_accuracy: 0.7695\n",
      "Epoch 5/30\n",
      "188/188 - 11s - loss: 0.4272 - accuracy: 0.7998 - val_loss: 0.4406 - val_accuracy: 0.7844\n",
      "Epoch 6/30\n",
      "188/188 - 11s - loss: 0.4120 - accuracy: 0.8039 - val_loss: 0.4190 - val_accuracy: 0.8039\n",
      "Epoch 7/30\n",
      "188/188 - 11s - loss: 0.3772 - accuracy: 0.8206 - val_loss: 0.4155 - val_accuracy: 0.8114\n",
      "Epoch 8/30\n",
      "188/188 - 11s - loss: 0.3487 - accuracy: 0.8334 - val_loss: 0.4055 - val_accuracy: 0.8114\n",
      "Epoch 9/30\n",
      "188/188 - 11s - loss: 0.3352 - accuracy: 0.8446 - val_loss: 0.4190 - val_accuracy: 0.8024\n",
      "Epoch 10/30\n",
      "188/188 - 11s - loss: 0.3156 - accuracy: 0.8597 - val_loss: 0.3821 - val_accuracy: 0.8249\n",
      "Epoch 11/30\n",
      "188/188 - 11s - loss: 0.2940 - accuracy: 0.8661 - val_loss: 0.3637 - val_accuracy: 0.8473\n",
      "Epoch 12/30\n",
      "188/188 - 11s - loss: 0.2882 - accuracy: 0.8732 - val_loss: 0.3953 - val_accuracy: 0.8293\n",
      "Epoch 13/30\n",
      "188/188 - 11s - loss: 0.2720 - accuracy: 0.8791 - val_loss: 0.3614 - val_accuracy: 0.8458\n",
      "Epoch 14/30\n",
      "188/188 - 11s - loss: 0.2514 - accuracy: 0.8869 - val_loss: 0.3619 - val_accuracy: 0.8473\n",
      "Epoch 15/30\n",
      "188/188 - 11s - loss: 0.2321 - accuracy: 0.8944 - val_loss: 0.3905 - val_accuracy: 0.8578\n",
      "Epoch 16/30\n",
      "188/188 - 11s - loss: 0.2207 - accuracy: 0.9019 - val_loss: 0.3884 - val_accuracy: 0.8518\n",
      "Epoch 17/30\n",
      "188/188 - 11s - loss: 0.2047 - accuracy: 0.9042 - val_loss: 0.3849 - val_accuracy: 0.8608\n",
      "Epoch 18/30\n",
      "188/188 - 11s - loss: 0.2072 - accuracy: 0.9085 - val_loss: 0.3734 - val_accuracy: 0.8578\n",
      "Epoch 19/30\n",
      "188/188 - 11s - loss: 0.1899 - accuracy: 0.9114 - val_loss: 0.4081 - val_accuracy: 0.8713\n",
      "Epoch 20/30\n",
      "188/188 - 11s - loss: 0.1769 - accuracy: 0.9219 - val_loss: 0.4054 - val_accuracy: 0.8638\n",
      "Epoch 21/30\n",
      "188/188 - 11s - loss: 0.1779 - accuracy: 0.9220 - val_loss: 0.4053 - val_accuracy: 0.8518\n",
      "Epoch 22/30\n",
      "188/188 - 11s - loss: 0.1618 - accuracy: 0.9297 - val_loss: 0.3919 - val_accuracy: 0.8638\n",
      "Epoch 23/30\n",
      "188/188 - 11s - loss: 0.1680 - accuracy: 0.9257 - val_loss: 0.4362 - val_accuracy: 0.8623\n",
      "Epoch 24/30\n",
      "188/188 - 11s - loss: 0.1610 - accuracy: 0.9257 - val_loss: 0.4071 - val_accuracy: 0.8638\n",
      "Epoch 25/30\n",
      "188/188 - 11s - loss: 0.1512 - accuracy: 0.9370 - val_loss: 0.4374 - val_accuracy: 0.8623\n",
      "Epoch 26/30\n",
      "188/188 - 11s - loss: 0.1541 - accuracy: 0.9349 - val_loss: 0.4388 - val_accuracy: 0.8668\n",
      "Epoch 27/30\n",
      "188/188 - 11s - loss: 0.1534 - accuracy: 0.9327 - val_loss: 0.4628 - val_accuracy: 0.8533\n",
      "Epoch 28/30\n",
      "188/188 - 11s - loss: 0.1566 - accuracy: 0.9310 - val_loss: 0.4593 - val_accuracy: 0.8623\n",
      "Epoch 29/30\n",
      "188/188 - 11s - loss: 0.1424 - accuracy: 0.9360 - val_loss: 0.4822 - val_accuracy: 0.8593\n",
      "Epoch 30/30\n",
      "188/188 - 11s - loss: 0.1446 - accuracy: 0.9384 - val_loss: 0.5113 - val_accuracy: 0.8548\n",
      "HVLV_CNN_LSTM: Fold 3 : f1_macroscore: 0.8136\n",
      "HVLV_CNN_LSTM: Fold 3 : f1_weightedscore: 0.8336\n",
      "HVLV_CNN_LSTM: Fold 3 : acc: 0.8354\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d (ConvLSTM2D)    (None, 5, 32, 32, 16)     11008     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 5, 32, 32, 16)     64        \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, 5, 32, 32, 32)     55424     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 5, 32, 32, 32)     128       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 163840)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 163840)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               83886592  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 83,954,242\n",
      "Trainable params: 83,954,146\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "188/188 - 11s - loss: 0.9980 - accuracy: 0.6555 - val_loss: 0.6132 - val_accuracy: 0.7156\n",
      "Epoch 2/30\n",
      "188/188 - 11s - loss: 0.5597 - accuracy: 0.7138 - val_loss: 0.5202 - val_accuracy: 0.7455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "188/188 - 11s - loss: 0.5105 - accuracy: 0.7441 - val_loss: 0.4826 - val_accuracy: 0.7620\n",
      "Epoch 4/30\n",
      "188/188 - 11s - loss: 0.4853 - accuracy: 0.7588 - val_loss: 0.4679 - val_accuracy: 0.7575\n",
      "Epoch 5/30\n",
      "188/188 - 11s - loss: 0.4519 - accuracy: 0.7789 - val_loss: 0.4860 - val_accuracy: 0.7620\n",
      "Epoch 6/30\n",
      "188/188 - 11s - loss: 0.4309 - accuracy: 0.7901 - val_loss: 0.4675 - val_accuracy: 0.7605\n",
      "Epoch 7/30\n",
      "188/188 - 11s - loss: 0.3970 - accuracy: 0.8101 - val_loss: 0.4583 - val_accuracy: 0.7964\n",
      "Epoch 8/30\n",
      "188/188 - 11s - loss: 0.3833 - accuracy: 0.8161 - val_loss: 0.4272 - val_accuracy: 0.7979\n",
      "Epoch 9/30\n",
      "188/188 - 11s - loss: 0.3594 - accuracy: 0.8256 - val_loss: 0.4396 - val_accuracy: 0.7994\n",
      "Epoch 10/30\n",
      "188/188 - 11s - loss: 0.3499 - accuracy: 0.8339 - val_loss: 0.4367 - val_accuracy: 0.8114\n",
      "Epoch 11/30\n",
      "188/188 - 11s - loss: 0.3279 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.7964\n",
      "Epoch 12/30\n",
      "188/188 - 11s - loss: 0.3101 - accuracy: 0.8497 - val_loss: 0.4569 - val_accuracy: 0.8159\n",
      "Epoch 13/30\n",
      "188/188 - 11s - loss: 0.3014 - accuracy: 0.8612 - val_loss: 0.4402 - val_accuracy: 0.7994\n",
      "Epoch 14/30\n",
      "188/188 - 11s - loss: 0.2905 - accuracy: 0.8586 - val_loss: 0.4669 - val_accuracy: 0.8234\n",
      "Epoch 15/30\n",
      "188/188 - 11s - loss: 0.2663 - accuracy: 0.8727 - val_loss: 0.4841 - val_accuracy: 0.8054\n",
      "Epoch 16/30\n",
      "188/188 - 11s - loss: 0.2572 - accuracy: 0.8781 - val_loss: 0.4688 - val_accuracy: 0.8189\n",
      "Epoch 17/30\n",
      "188/188 - 11s - loss: 0.2555 - accuracy: 0.8817 - val_loss: 0.4873 - val_accuracy: 0.8054\n",
      "Epoch 18/30\n",
      "188/188 - 11s - loss: 0.2388 - accuracy: 0.8851 - val_loss: 0.5148 - val_accuracy: 0.8129\n",
      "Epoch 19/30\n",
      "188/188 - 11s - loss: 0.2412 - accuracy: 0.8846 - val_loss: 0.5255 - val_accuracy: 0.7979\n",
      "Epoch 20/30\n",
      "188/188 - 11s - loss: 0.2266 - accuracy: 0.8921 - val_loss: 0.4913 - val_accuracy: 0.8278\n",
      "Epoch 21/30\n",
      "188/188 - 11s - loss: 0.2144 - accuracy: 0.8947 - val_loss: 0.5123 - val_accuracy: 0.8159\n",
      "Epoch 22/30\n",
      "188/188 - 11s - loss: 0.1999 - accuracy: 0.9040 - val_loss: 0.4755 - val_accuracy: 0.8234\n",
      "Epoch 23/30\n",
      "188/188 - 11s - loss: 0.1991 - accuracy: 0.9060 - val_loss: 0.5501 - val_accuracy: 0.8249\n",
      "Epoch 24/30\n",
      "188/188 - 11s - loss: 0.1930 - accuracy: 0.9109 - val_loss: 0.5620 - val_accuracy: 0.8159\n",
      "Epoch 25/30\n",
      "188/188 - 11s - loss: 0.1916 - accuracy: 0.9080 - val_loss: 0.6298 - val_accuracy: 0.7784\n",
      "Epoch 26/30\n",
      "188/188 - 11s - loss: 0.1868 - accuracy: 0.9104 - val_loss: 0.5128 - val_accuracy: 0.8144\n",
      "Epoch 27/30\n",
      "188/188 - 11s - loss: 0.2040 - accuracy: 0.9077 - val_loss: 0.5374 - val_accuracy: 0.8234\n",
      "Epoch 28/30\n",
      "188/188 - 11s - loss: 0.1765 - accuracy: 0.9167 - val_loss: 0.5017 - val_accuracy: 0.8368\n",
      "Epoch 29/30\n",
      "188/188 - 11s - loss: 0.1787 - accuracy: 0.9150 - val_loss: 0.5198 - val_accuracy: 0.8189\n",
      "Epoch 30/30\n",
      "188/188 - 11s - loss: 0.1625 - accuracy: 0.9215 - val_loss: 0.5540 - val_accuracy: 0.8293\n",
      "HVLV_CNN_LSTM: Fold 4 : f1_macroscore: 0.8381\n",
      "HVLV_CNN_LSTM: Fold 4 : f1_weightedscore: 0.8535\n",
      "HVLV_CNN_LSTM: Fold 4 : acc: 0.8529\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d (ConvLSTM2D)    (None, 5, 32, 32, 16)     11008     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 5, 32, 32, 16)     64        \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, 5, 32, 32, 32)     55424     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 5, 32, 32, 32)     128       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 163840)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 163840)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               83886592  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 83,954,242\n",
      "Trainable params: 83,954,146\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "188/188 - 11s - loss: 1.0723 - accuracy: 0.6610 - val_loss: 0.5940 - val_accuracy: 0.7111\n",
      "Epoch 2/30\n",
      "188/188 - 11s - loss: 0.5799 - accuracy: 0.7205 - val_loss: 0.5203 - val_accuracy: 0.7515\n",
      "Epoch 3/30\n",
      "188/188 - 11s - loss: 0.5289 - accuracy: 0.7436 - val_loss: 0.4904 - val_accuracy: 0.7605\n",
      "Epoch 4/30\n",
      "188/188 - 11s - loss: 0.4856 - accuracy: 0.7674 - val_loss: 0.4809 - val_accuracy: 0.7485\n",
      "Epoch 5/30\n",
      "188/188 - 11s - loss: 0.4626 - accuracy: 0.7791 - val_loss: 0.4633 - val_accuracy: 0.7710\n",
      "Epoch 6/30\n",
      "188/188 - 11s - loss: 0.4238 - accuracy: 0.7983 - val_loss: 0.4343 - val_accuracy: 0.7889\n",
      "Epoch 7/30\n",
      "188/188 - 11s - loss: 0.4030 - accuracy: 0.8164 - val_loss: 0.4221 - val_accuracy: 0.7889\n",
      "Epoch 8/30\n",
      "188/188 - 11s - loss: 0.3858 - accuracy: 0.8171 - val_loss: 0.4128 - val_accuracy: 0.7964\n",
      "Epoch 9/30\n",
      "188/188 - 11s - loss: 0.3656 - accuracy: 0.8294 - val_loss: 0.3978 - val_accuracy: 0.8069\n",
      "Epoch 10/30\n",
      "188/188 - 11s - loss: 0.3613 - accuracy: 0.8349 - val_loss: 0.4062 - val_accuracy: 0.8039\n",
      "Epoch 11/30\n",
      "188/188 - 11s - loss: 0.3339 - accuracy: 0.8384 - val_loss: 0.4108 - val_accuracy: 0.7964\n",
      "Epoch 12/30\n",
      "188/188 - 11s - loss: 0.3176 - accuracy: 0.8524 - val_loss: 0.3825 - val_accuracy: 0.8099\n",
      "Epoch 13/30\n",
      "188/188 - 11s - loss: 0.2994 - accuracy: 0.8601 - val_loss: 0.3803 - val_accuracy: 0.8308\n",
      "Epoch 14/30\n",
      "188/188 - 11s - loss: 0.2826 - accuracy: 0.8699 - val_loss: 0.4067 - val_accuracy: 0.8234\n",
      "Epoch 15/30\n",
      "188/188 - 11s - loss: 0.2682 - accuracy: 0.8781 - val_loss: 0.3948 - val_accuracy: 0.8278\n",
      "Epoch 16/30\n",
      "188/188 - 11s - loss: 0.2644 - accuracy: 0.8754 - val_loss: 0.4164 - val_accuracy: 0.8204\n",
      "Epoch 17/30\n",
      "188/188 - 11s - loss: 0.2523 - accuracy: 0.8871 - val_loss: 0.4115 - val_accuracy: 0.8398\n",
      "Epoch 18/30\n",
      "188/188 - 11s - loss: 0.2465 - accuracy: 0.8856 - val_loss: 0.4303 - val_accuracy: 0.8204\n",
      "Epoch 19/30\n",
      "188/188 - 11s - loss: 0.2315 - accuracy: 0.8914 - val_loss: 0.4385 - val_accuracy: 0.8368\n",
      "Epoch 20/30\n",
      "188/188 - 11s - loss: 0.2316 - accuracy: 0.8919 - val_loss: 0.4437 - val_accuracy: 0.8189\n",
      "Epoch 21/30\n",
      "188/188 - 11s - loss: 0.2234 - accuracy: 0.8964 - val_loss: 0.4094 - val_accuracy: 0.8473\n",
      "Epoch 22/30\n",
      "188/188 - 11s - loss: 0.2052 - accuracy: 0.9040 - val_loss: 0.4248 - val_accuracy: 0.8518\n",
      "Epoch 23/30\n",
      "188/188 - 11s - loss: 0.2064 - accuracy: 0.9069 - val_loss: 0.4938 - val_accuracy: 0.8353\n",
      "Epoch 24/30\n",
      "188/188 - 11s - loss: 0.1958 - accuracy: 0.9104 - val_loss: 0.4752 - val_accuracy: 0.8278\n",
      "Epoch 25/30\n",
      "188/188 - 11s - loss: 0.1944 - accuracy: 0.9105 - val_loss: 0.4707 - val_accuracy: 0.8398\n",
      "Epoch 26/30\n",
      "188/188 - 11s - loss: 0.1866 - accuracy: 0.9130 - val_loss: 0.4962 - val_accuracy: 0.8353\n",
      "Epoch 27/30\n",
      "188/188 - 11s - loss: 0.1700 - accuracy: 0.9219 - val_loss: 0.4746 - val_accuracy: 0.8608\n",
      "Epoch 28/30\n",
      "188/188 - 11s - loss: 0.1769 - accuracy: 0.9214 - val_loss: 0.4890 - val_accuracy: 0.8503\n",
      "Epoch 29/30\n",
      "188/188 - 11s - loss: 0.1667 - accuracy: 0.9254 - val_loss: 0.4331 - val_accuracy: 0.8653\n",
      "Epoch 30/30\n",
      "188/188 - 11s - loss: 0.1745 - accuracy: 0.9192 - val_loss: 0.4824 - val_accuracy: 0.8563\n",
      "HVLV_CNN_LSTM: Fold 5 : f1_macroscore: 0.7952\n",
      "HVLV_CNN_LSTM: Fold 5 : f1_weightedscore: 0.8190\n",
      "HVLV_CNN_LSTM: Fold 5 : acc: 0.8232\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d (ConvLSTM2D)    (None, 5, 32, 32, 16)     11008     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 5, 32, 32, 16)     64        \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, 5, 32, 32, 32)     55424     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 5, 32, 32, 32)     128       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 163840)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 163840)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               83886592  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 83,954,242\n",
      "Trainable params: 83,954,146\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "188/188 - 11s - loss: 1.1148 - accuracy: 0.6570 - val_loss: 0.5732 - val_accuracy: 0.7305\n",
      "Epoch 2/30\n",
      "188/188 - 11s - loss: 0.5896 - accuracy: 0.7136 - val_loss: 0.4915 - val_accuracy: 0.7620\n",
      "Epoch 3/30\n",
      "188/188 - 11s - loss: 0.5275 - accuracy: 0.7391 - val_loss: 0.4969 - val_accuracy: 0.7530\n",
      "Epoch 4/30\n",
      "188/188 - 11s - loss: 0.4955 - accuracy: 0.7545 - val_loss: 0.4723 - val_accuracy: 0.7590\n",
      "Epoch 5/30\n",
      "188/188 - 11s - loss: 0.4551 - accuracy: 0.7806 - val_loss: 0.4411 - val_accuracy: 0.7859\n",
      "Epoch 6/30\n",
      "188/188 - 11s - loss: 0.4359 - accuracy: 0.7921 - val_loss: 0.4092 - val_accuracy: 0.7994\n",
      "Epoch 7/30\n",
      "188/188 - 11s - loss: 0.4088 - accuracy: 0.8028 - val_loss: 0.3997 - val_accuracy: 0.8174\n",
      "Epoch 8/30\n",
      "188/188 - 11s - loss: 0.3862 - accuracy: 0.8183 - val_loss: 0.4024 - val_accuracy: 0.8009\n",
      "Epoch 9/30\n",
      "188/188 - 11s - loss: 0.3710 - accuracy: 0.8258 - val_loss: 0.3842 - val_accuracy: 0.8009\n",
      "Epoch 10/30\n",
      "188/188 - 11s - loss: 0.3612 - accuracy: 0.8298 - val_loss: 0.3909 - val_accuracy: 0.8039\n",
      "Epoch 11/30\n",
      "188/188 - 11s - loss: 0.3496 - accuracy: 0.8329 - val_loss: 0.3718 - val_accuracy: 0.8174\n",
      "Epoch 12/30\n",
      "188/188 - 11s - loss: 0.3150 - accuracy: 0.8569 - val_loss: 0.3965 - val_accuracy: 0.8189\n",
      "Epoch 13/30\n",
      "188/188 - 11s - loss: 0.3205 - accuracy: 0.8491 - val_loss: 0.3701 - val_accuracy: 0.8338\n",
      "Epoch 14/30\n",
      "188/188 - 11s - loss: 0.3043 - accuracy: 0.8574 - val_loss: 0.3790 - val_accuracy: 0.8338\n",
      "Epoch 15/30\n",
      "188/188 - 11s - loss: 0.2831 - accuracy: 0.8711 - val_loss: 0.3849 - val_accuracy: 0.8219\n",
      "Epoch 16/30\n",
      "188/188 - 11s - loss: 0.2725 - accuracy: 0.8712 - val_loss: 0.3922 - val_accuracy: 0.8428\n",
      "Epoch 17/30\n",
      "188/188 - 11s - loss: 0.2654 - accuracy: 0.8781 - val_loss: 0.3908 - val_accuracy: 0.8353\n",
      "Epoch 18/30\n",
      "188/188 - 11s - loss: 0.2532 - accuracy: 0.8832 - val_loss: 0.3910 - val_accuracy: 0.8398\n",
      "Epoch 19/30\n",
      "188/188 - 11s - loss: 0.2451 - accuracy: 0.8886 - val_loss: 0.3682 - val_accuracy: 0.8518\n",
      "Epoch 20/30\n",
      "188/188 - 11s - loss: 0.2329 - accuracy: 0.8919 - val_loss: 0.3845 - val_accuracy: 0.8458\n",
      "Epoch 21/30\n",
      "188/188 - 11s - loss: 0.2285 - accuracy: 0.8951 - val_loss: 0.3955 - val_accuracy: 0.8413\n",
      "Epoch 22/30\n",
      "188/188 - 11s - loss: 0.2167 - accuracy: 0.9070 - val_loss: 0.3920 - val_accuracy: 0.8608\n",
      "Epoch 23/30\n",
      "188/188 - 11s - loss: 0.2084 - accuracy: 0.9055 - val_loss: 0.4012 - val_accuracy: 0.8428\n",
      "Epoch 24/30\n",
      "188/188 - 11s - loss: 0.2038 - accuracy: 0.9074 - val_loss: 0.4100 - val_accuracy: 0.8548\n",
      "Epoch 25/30\n",
      "188/188 - 11s - loss: 0.1959 - accuracy: 0.9099 - val_loss: 0.4012 - val_accuracy: 0.8548\n",
      "Epoch 26/30\n",
      "188/188 - 11s - loss: 0.2010 - accuracy: 0.9075 - val_loss: 0.4306 - val_accuracy: 0.8608\n",
      "Epoch 27/30\n",
      "188/188 - 11s - loss: 0.1890 - accuracy: 0.9107 - val_loss: 0.4082 - val_accuracy: 0.8623\n",
      "Epoch 28/30\n",
      "188/188 - 11s - loss: 0.1687 - accuracy: 0.9227 - val_loss: 0.4014 - val_accuracy: 0.8548\n",
      "Epoch 29/30\n",
      "188/188 - 11s - loss: 0.1743 - accuracy: 0.9205 - val_loss: 0.4306 - val_accuracy: 0.8578\n",
      "Epoch 30/30\n",
      "188/188 - 11s - loss: 0.1826 - accuracy: 0.9159 - val_loss: 0.4455 - val_accuracy: 0.8623\n",
      "HVLV_CNN_LSTM: Fold 6 : f1_macroscore: 0.8121\n",
      "HVLV_CNN_LSTM: Fold 6 : f1_weightedscore: 0.8335\n",
      "HVLV_CNN_LSTM: Fold 6 : acc: 0.8367\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d (ConvLSTM2D)    (None, 5, 32, 32, 16)     11008     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 5, 32, 32, 16)     64        \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, 5, 32, 32, 32)     55424     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 5, 32, 32, 32)     128       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 163840)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 163840)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               83886592  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 83,954,242\n",
      "Trainable params: 83,954,146\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "188/188 - 11s - loss: 1.1194 - accuracy: 0.6542 - val_loss: 0.6304 - val_accuracy: 0.7275\n",
      "Epoch 2/30\n",
      "188/188 - 11s - loss: 0.5923 - accuracy: 0.7145 - val_loss: 0.5261 - val_accuracy: 0.7410\n",
      "Epoch 3/30\n",
      "188/188 - 11s - loss: 0.5279 - accuracy: 0.7376 - val_loss: 0.5103 - val_accuracy: 0.7590\n",
      "Epoch 4/30\n",
      "188/188 - 11s - loss: 0.4855 - accuracy: 0.7681 - val_loss: 0.4592 - val_accuracy: 0.7575\n",
      "Epoch 5/30\n",
      "188/188 - 11s - loss: 0.4615 - accuracy: 0.7751 - val_loss: 0.4656 - val_accuracy: 0.7769\n",
      "Epoch 6/30\n",
      "188/188 - 11s - loss: 0.4414 - accuracy: 0.7913 - val_loss: 0.4524 - val_accuracy: 0.7754\n",
      "Epoch 7/30\n",
      "188/188 - 11s - loss: 0.4097 - accuracy: 0.8029 - val_loss: 0.4535 - val_accuracy: 0.7769\n",
      "Epoch 8/30\n",
      "188/188 - 11s - loss: 0.3975 - accuracy: 0.8114 - val_loss: 0.4645 - val_accuracy: 0.7784\n",
      "Epoch 9/30\n",
      "188/188 - 11s - loss: 0.3838 - accuracy: 0.8149 - val_loss: 0.4366 - val_accuracy: 0.7769\n",
      "Epoch 10/30\n",
      "188/188 - 11s - loss: 0.3677 - accuracy: 0.8231 - val_loss: 0.4457 - val_accuracy: 0.7934\n",
      "Epoch 11/30\n",
      "188/188 - 11s - loss: 0.3479 - accuracy: 0.8357 - val_loss: 0.4313 - val_accuracy: 0.7994\n",
      "Epoch 12/30\n",
      "188/188 - 11s - loss: 0.3370 - accuracy: 0.8411 - val_loss: 0.4203 - val_accuracy: 0.8144\n",
      "Epoch 13/30\n",
      "188/188 - 11s - loss: 0.3119 - accuracy: 0.8529 - val_loss: 0.4631 - val_accuracy: 0.7949\n",
      "Epoch 14/30\n",
      "188/188 - 11s - loss: 0.3025 - accuracy: 0.8582 - val_loss: 0.4347 - val_accuracy: 0.8024\n",
      "Epoch 15/30\n",
      "188/188 - 11s - loss: 0.2917 - accuracy: 0.8679 - val_loss: 0.4399 - val_accuracy: 0.7964\n",
      "Epoch 16/30\n",
      "188/188 - 11s - loss: 0.2816 - accuracy: 0.8717 - val_loss: 0.4217 - val_accuracy: 0.8144\n",
      "Epoch 17/30\n",
      "188/188 - 11s - loss: 0.2783 - accuracy: 0.8691 - val_loss: 0.4588 - val_accuracy: 0.8234\n",
      "Epoch 18/30\n",
      "188/188 - 11s - loss: 0.2527 - accuracy: 0.8804 - val_loss: 0.4557 - val_accuracy: 0.8069\n",
      "Epoch 19/30\n",
      "188/188 - 11s - loss: 0.2501 - accuracy: 0.8824 - val_loss: 0.4797 - val_accuracy: 0.8069\n",
      "Epoch 20/30\n",
      "188/188 - 11s - loss: 0.2456 - accuracy: 0.8839 - val_loss: 0.4804 - val_accuracy: 0.8129\n",
      "Epoch 21/30\n",
      "188/188 - 11s - loss: 0.2429 - accuracy: 0.8889 - val_loss: 0.5069 - val_accuracy: 0.8159\n",
      "Epoch 22/30\n",
      "188/188 - 11s - loss: 0.2308 - accuracy: 0.8932 - val_loss: 0.4952 - val_accuracy: 0.8159\n",
      "Epoch 23/30\n",
      "188/188 - 11s - loss: 0.2164 - accuracy: 0.8982 - val_loss: 0.5005 - val_accuracy: 0.8189\n",
      "Epoch 24/30\n",
      "188/188 - 11s - loss: 0.2127 - accuracy: 0.8976 - val_loss: 0.5129 - val_accuracy: 0.8308\n",
      "Epoch 25/30\n",
      "188/188 - 11s - loss: 0.2150 - accuracy: 0.9014 - val_loss: 0.5011 - val_accuracy: 0.8159\n",
      "Epoch 26/30\n",
      "188/188 - 11s - loss: 0.2185 - accuracy: 0.8977 - val_loss: 0.5246 - val_accuracy: 0.8323\n",
      "Epoch 27/30\n",
      "188/188 - 11s - loss: 0.1861 - accuracy: 0.9144 - val_loss: 0.5057 - val_accuracy: 0.8219\n",
      "Epoch 28/30\n",
      "188/188 - 11s - loss: 0.1869 - accuracy: 0.9172 - val_loss: 0.5102 - val_accuracy: 0.8234\n",
      "Epoch 29/30\n",
      "188/188 - 11s - loss: 0.1851 - accuracy: 0.9125 - val_loss: 0.5145 - val_accuracy: 0.8278\n",
      "Epoch 30/30\n",
      "188/188 - 11s - loss: 0.1743 - accuracy: 0.9209 - val_loss: 0.5380 - val_accuracy: 0.8204\n",
      "HVLV_CNN_LSTM: Fold 7 : f1_macroscore: 0.8083\n",
      "HVLV_CNN_LSTM: Fold 7 : f1_weightedscore: 0.8286\n",
      "HVLV_CNN_LSTM: Fold 7 : acc: 0.8300\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d (ConvLSTM2D)    (None, 5, 32, 32, 16)     11008     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 5, 32, 32, 16)     64        \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, 5, 32, 32, 32)     55424     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 5, 32, 32, 32)     128       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 163840)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 163840)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               83886592  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 83,954,242\n",
      "Trainable params: 83,954,146\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "188/188 - 11s - loss: 1.0941 - accuracy: 0.6495 - val_loss: 0.5767 - val_accuracy: 0.7216\n",
      "Epoch 2/30\n",
      "188/188 - 11s - loss: 0.6024 - accuracy: 0.7093 - val_loss: 0.5035 - val_accuracy: 0.7365\n",
      "Epoch 3/30\n",
      "188/188 - 11s - loss: 0.5330 - accuracy: 0.7335 - val_loss: 0.4846 - val_accuracy: 0.7545\n",
      "Epoch 4/30\n",
      "188/188 - 11s - loss: 0.4897 - accuracy: 0.7573 - val_loss: 0.4950 - val_accuracy: 0.7575\n",
      "Epoch 5/30\n",
      "188/188 - 11s - loss: 0.4636 - accuracy: 0.7779 - val_loss: 0.4409 - val_accuracy: 0.7754\n",
      "Epoch 6/30\n",
      "188/188 - 11s - loss: 0.4480 - accuracy: 0.7848 - val_loss: 0.4381 - val_accuracy: 0.7814\n",
      "Epoch 7/30\n",
      "188/188 - 11s - loss: 0.4129 - accuracy: 0.8009 - val_loss: 0.4241 - val_accuracy: 0.7814\n",
      "Epoch 8/30\n",
      "188/188 - 11s - loss: 0.3890 - accuracy: 0.8113 - val_loss: 0.4041 - val_accuracy: 0.8009\n",
      "Epoch 9/30\n",
      "188/188 - 11s - loss: 0.3607 - accuracy: 0.8268 - val_loss: 0.4338 - val_accuracy: 0.7769\n",
      "Epoch 10/30\n",
      "188/188 - 11s - loss: 0.3558 - accuracy: 0.8314 - val_loss: 0.4108 - val_accuracy: 0.7994\n",
      "Epoch 11/30\n",
      "188/188 - 11s - loss: 0.3364 - accuracy: 0.8424 - val_loss: 0.4399 - val_accuracy: 0.7680\n",
      "Epoch 12/30\n",
      "188/188 - 11s - loss: 0.3294 - accuracy: 0.8501 - val_loss: 0.3764 - val_accuracy: 0.8144\n",
      "Epoch 13/30\n",
      "188/188 - 11s - loss: 0.3042 - accuracy: 0.8594 - val_loss: 0.3942 - val_accuracy: 0.8054\n",
      "Epoch 14/30\n",
      "188/188 - 11s - loss: 0.2900 - accuracy: 0.8692 - val_loss: 0.3932 - val_accuracy: 0.8129\n",
      "Epoch 15/30\n",
      "188/188 - 11s - loss: 0.2788 - accuracy: 0.8701 - val_loss: 0.3623 - val_accuracy: 0.8189\n",
      "Epoch 16/30\n",
      "188/188 - 11s - loss: 0.2649 - accuracy: 0.8754 - val_loss: 0.4042 - val_accuracy: 0.8114\n",
      "Epoch 17/30\n",
      "188/188 - 11s - loss: 0.2679 - accuracy: 0.8809 - val_loss: 0.4053 - val_accuracy: 0.8293\n",
      "Epoch 18/30\n",
      "188/188 - 11s - loss: 0.2445 - accuracy: 0.8856 - val_loss: 0.3935 - val_accuracy: 0.8174\n",
      "Epoch 19/30\n",
      "188/188 - 11s - loss: 0.2483 - accuracy: 0.8856 - val_loss: 0.4122 - val_accuracy: 0.8204\n",
      "Epoch 20/30\n",
      "188/188 - 11s - loss: 0.2194 - accuracy: 0.8969 - val_loss: 0.4172 - val_accuracy: 0.8278\n",
      "Epoch 21/30\n",
      "188/188 - 11s - loss: 0.2195 - accuracy: 0.8949 - val_loss: 0.3965 - val_accuracy: 0.8368\n",
      "Epoch 22/30\n",
      "188/188 - 11s - loss: 0.2200 - accuracy: 0.8934 - val_loss: 0.4001 - val_accuracy: 0.8323\n",
      "Epoch 23/30\n",
      "188/188 - 11s - loss: 0.2115 - accuracy: 0.8987 - val_loss: 0.4475 - val_accuracy: 0.8159\n",
      "Epoch 24/30\n",
      "188/188 - 11s - loss: 0.1957 - accuracy: 0.9069 - val_loss: 0.4132 - val_accuracy: 0.8249\n",
      "Epoch 25/30\n",
      "188/188 - 11s - loss: 0.1923 - accuracy: 0.9074 - val_loss: 0.4891 - val_accuracy: 0.8338\n",
      "Epoch 26/30\n",
      "188/188 - 11s - loss: 0.1852 - accuracy: 0.9115 - val_loss: 0.4662 - val_accuracy: 0.8174\n",
      "Epoch 27/30\n",
      "188/188 - 11s - loss: 0.1754 - accuracy: 0.9165 - val_loss: 0.4772 - val_accuracy: 0.8398\n",
      "Epoch 28/30\n",
      "188/188 - 11s - loss: 0.1798 - accuracy: 0.9132 - val_loss: 0.4303 - val_accuracy: 0.8338\n",
      "Epoch 29/30\n",
      "188/188 - 11s - loss: 0.1710 - accuracy: 0.9147 - val_loss: 0.4789 - val_accuracy: 0.8204\n",
      "Epoch 30/30\n",
      "188/188 - 11s - loss: 0.1639 - accuracy: 0.9190 - val_loss: 0.4553 - val_accuracy: 0.8338\n",
      "HVLV_CNN_LSTM: Fold 8 : f1_macroscore: 0.7725\n",
      "HVLV_CNN_LSTM: Fold 8 : f1_weightedscore: 0.7987\n",
      "HVLV_CNN_LSTM: Fold 8 : acc: 0.8030\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d (ConvLSTM2D)    (None, 5, 32, 32, 16)     11008     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 5, 32, 32, 16)     64        \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, 5, 32, 32, 32)     55424     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 5, 32, 32, 32)     128       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 163840)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 163840)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               83886592  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 83,954,242\n",
      "Trainable params: 83,954,146\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "188/188 - 12s - loss: 1.0424 - accuracy: 0.6570 - val_loss: 0.5971 - val_accuracy: 0.7126\n",
      "Epoch 2/30\n",
      "188/188 - 11s - loss: 0.5768 - accuracy: 0.7186 - val_loss: 0.5261 - val_accuracy: 0.7575\n",
      "Epoch 3/30\n",
      "188/188 - 11s - loss: 0.5348 - accuracy: 0.7395 - val_loss: 0.4781 - val_accuracy: 0.7605\n",
      "Epoch 4/30\n",
      "188/188 - 11s - loss: 0.4801 - accuracy: 0.7631 - val_loss: 0.4360 - val_accuracy: 0.7725\n",
      "Epoch 5/30\n",
      "188/188 - 11s - loss: 0.4421 - accuracy: 0.7804 - val_loss: 0.4419 - val_accuracy: 0.7829\n",
      "Epoch 6/30\n",
      "188/188 - 11s - loss: 0.4308 - accuracy: 0.7923 - val_loss: 0.4167 - val_accuracy: 0.7919\n",
      "Epoch 7/30\n",
      "188/188 - 11s - loss: 0.4106 - accuracy: 0.8024 - val_loss: 0.4019 - val_accuracy: 0.8009\n",
      "Epoch 8/30\n",
      "188/188 - 11s - loss: 0.3906 - accuracy: 0.8153 - val_loss: 0.4071 - val_accuracy: 0.8159\n",
      "Epoch 9/30\n",
      "188/188 - 11s - loss: 0.3745 - accuracy: 0.8219 - val_loss: 0.3920 - val_accuracy: 0.8234\n",
      "Epoch 10/30\n",
      "188/188 - 11s - loss: 0.3431 - accuracy: 0.8387 - val_loss: 0.3792 - val_accuracy: 0.8144\n",
      "Epoch 11/30\n",
      "188/188 - 11s - loss: 0.3186 - accuracy: 0.8469 - val_loss: 0.3724 - val_accuracy: 0.8249\n",
      "Epoch 12/30\n",
      "188/188 - 11s - loss: 0.3042 - accuracy: 0.8606 - val_loss: 0.3751 - val_accuracy: 0.8204\n",
      "Epoch 13/30\n",
      "188/188 - 11s - loss: 0.2917 - accuracy: 0.8611 - val_loss: 0.3509 - val_accuracy: 0.8338\n",
      "Epoch 14/30\n",
      "188/188 - 11s - loss: 0.2841 - accuracy: 0.8667 - val_loss: 0.3527 - val_accuracy: 0.8338\n",
      "Epoch 15/30\n",
      "188/188 - 11s - loss: 0.2677 - accuracy: 0.8742 - val_loss: 0.3849 - val_accuracy: 0.8383\n",
      "Epoch 16/30\n",
      "188/188 - 11s - loss: 0.2592 - accuracy: 0.8762 - val_loss: 0.3719 - val_accuracy: 0.8323\n",
      "Epoch 17/30\n",
      "188/188 - 11s - loss: 0.2575 - accuracy: 0.8792 - val_loss: 0.3789 - val_accuracy: 0.8278\n",
      "Epoch 18/30\n",
      "188/188 - 11s - loss: 0.2387 - accuracy: 0.8861 - val_loss: 0.3472 - val_accuracy: 0.8398\n",
      "Epoch 19/30\n",
      "188/188 - 11s - loss: 0.2234 - accuracy: 0.8987 - val_loss: 0.3475 - val_accuracy: 0.8563\n",
      "Epoch 20/30\n",
      "188/188 - 11s - loss: 0.2221 - accuracy: 0.8971 - val_loss: 0.3704 - val_accuracy: 0.8518\n",
      "Epoch 21/30\n",
      "188/188 - 11s - loss: 0.2084 - accuracy: 0.9014 - val_loss: 0.4015 - val_accuracy: 0.8458\n",
      "Epoch 22/30\n",
      "188/188 - 11s - loss: 0.2050 - accuracy: 0.9055 - val_loss: 0.3621 - val_accuracy: 0.8593\n",
      "Epoch 23/30\n",
      "188/188 - 11s - loss: 0.1912 - accuracy: 0.9090 - val_loss: 0.3747 - val_accuracy: 0.8533\n",
      "Epoch 24/30\n",
      "188/188 - 11s - loss: 0.1958 - accuracy: 0.9039 - val_loss: 0.3627 - val_accuracy: 0.8638\n",
      "Epoch 25/30\n",
      "188/188 - 11s - loss: 0.1852 - accuracy: 0.9124 - val_loss: 0.3999 - val_accuracy: 0.8488\n",
      "Epoch 26/30\n",
      "188/188 - 11s - loss: 0.1767 - accuracy: 0.9142 - val_loss: 0.4027 - val_accuracy: 0.8593\n",
      "Epoch 27/30\n",
      "188/188 - 11s - loss: 0.1830 - accuracy: 0.9107 - val_loss: 0.3987 - val_accuracy: 0.8653\n",
      "Epoch 28/30\n",
      "188/188 - 11s - loss: 0.1701 - accuracy: 0.9197 - val_loss: 0.4024 - val_accuracy: 0.8698\n",
      "Epoch 29/30\n",
      "188/188 - 11s - loss: 0.1736 - accuracy: 0.9197 - val_loss: 0.3685 - val_accuracy: 0.8772\n",
      "Epoch 30/30\n",
      "188/188 - 11s - loss: 0.1563 - accuracy: 0.9250 - val_loss: 0.4160 - val_accuracy: 0.8533\n",
      "HVLV_CNN_LSTM: Fold 9 : f1_macroscore: 0.8384\n",
      "HVLV_CNN_LSTM: Fold 9 : f1_weightedscore: 0.8562\n",
      "HVLV_CNN_LSTM: Fold 9 : acc: 0.8583\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d (ConvLSTM2D)    (None, 5, 32, 32, 16)     11008     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 5, 32, 32, 16)     64        \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, 5, 32, 32, 32)     55424     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 5, 32, 32, 32)     128       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 163840)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 163840)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               83886592  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 83,954,242\n",
      "Trainable params: 83,954,146\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "188/188 - 12s - loss: 1.0178 - accuracy: 0.6578 - val_loss: 0.5938 - val_accuracy: 0.7171\n",
      "Epoch 2/30\n",
      "188/188 - 11s - loss: 0.6102 - accuracy: 0.7001 - val_loss: 0.5113 - val_accuracy: 0.7350\n",
      "Epoch 3/30\n",
      "188/188 - 11s - loss: 0.5486 - accuracy: 0.7220 - val_loss: 0.4745 - val_accuracy: 0.7575\n",
      "Epoch 4/30\n",
      "188/188 - 11s - loss: 0.4984 - accuracy: 0.7466 - val_loss: 0.4783 - val_accuracy: 0.7545\n",
      "Epoch 5/30\n",
      "188/188 - 11s - loss: 0.4739 - accuracy: 0.7628 - val_loss: 0.4536 - val_accuracy: 0.7710\n",
      "Epoch 6/30\n",
      "188/188 - 11s - loss: 0.4473 - accuracy: 0.7759 - val_loss: 0.4484 - val_accuracy: 0.7844\n",
      "Epoch 7/30\n",
      "188/188 - 11s - loss: 0.4212 - accuracy: 0.7968 - val_loss: 0.4291 - val_accuracy: 0.7919\n",
      "Epoch 8/30\n",
      "188/188 - 11s - loss: 0.4097 - accuracy: 0.7956 - val_loss: 0.4327 - val_accuracy: 0.7979\n",
      "Epoch 9/30\n",
      "188/188 - 11s - loss: 0.3850 - accuracy: 0.8168 - val_loss: 0.4129 - val_accuracy: 0.7949\n",
      "Epoch 10/30\n",
      "188/188 - 11s - loss: 0.3744 - accuracy: 0.8233 - val_loss: 0.4374 - val_accuracy: 0.7844\n",
      "Epoch 11/30\n",
      "188/188 - 11s - loss: 0.3619 - accuracy: 0.8266 - val_loss: 0.4060 - val_accuracy: 0.8099\n",
      "Epoch 12/30\n",
      "188/188 - 11s - loss: 0.3395 - accuracy: 0.8367 - val_loss: 0.4329 - val_accuracy: 0.7919\n",
      "Epoch 13/30\n",
      "188/188 - 11s - loss: 0.3298 - accuracy: 0.8434 - val_loss: 0.4058 - val_accuracy: 0.8069\n",
      "Epoch 14/30\n",
      "188/188 - 11s - loss: 0.3115 - accuracy: 0.8526 - val_loss: 0.4059 - val_accuracy: 0.8159\n",
      "Epoch 15/30\n",
      "188/188 - 11s - loss: 0.3064 - accuracy: 0.8561 - val_loss: 0.3829 - val_accuracy: 0.8174\n",
      "Epoch 16/30\n",
      "188/188 - 11s - loss: 0.2906 - accuracy: 0.8586 - val_loss: 0.4105 - val_accuracy: 0.8129\n",
      "Epoch 17/30\n",
      "188/188 - 11s - loss: 0.2818 - accuracy: 0.8717 - val_loss: 0.4065 - val_accuracy: 0.8039\n",
      "Epoch 18/30\n",
      "188/188 - 11s - loss: 0.2676 - accuracy: 0.8724 - val_loss: 0.3817 - val_accuracy: 0.8278\n",
      "Epoch 19/30\n",
      "188/188 - 11s - loss: 0.2612 - accuracy: 0.8786 - val_loss: 0.3907 - val_accuracy: 0.8368\n",
      "Epoch 20/30\n",
      "188/188 - 11s - loss: 0.2492 - accuracy: 0.8826 - val_loss: 0.3836 - val_accuracy: 0.8219\n",
      "Epoch 21/30\n",
      "188/188 - 11s - loss: 0.2420 - accuracy: 0.8802 - val_loss: 0.4117 - val_accuracy: 0.8278\n",
      "Epoch 22/30\n",
      "188/188 - 11s - loss: 0.2434 - accuracy: 0.8876 - val_loss: 0.3962 - val_accuracy: 0.8293\n",
      "Epoch 23/30\n",
      "188/188 - 11s - loss: 0.2315 - accuracy: 0.8881 - val_loss: 0.4193 - val_accuracy: 0.8144\n",
      "Epoch 24/30\n",
      "188/188 - 11s - loss: 0.2296 - accuracy: 0.8891 - val_loss: 0.4121 - val_accuracy: 0.8398\n",
      "Epoch 25/30\n",
      "188/188 - 11s - loss: 0.2145 - accuracy: 0.8974 - val_loss: 0.4194 - val_accuracy: 0.8563\n",
      "Epoch 26/30\n",
      "188/188 - 11s - loss: 0.2088 - accuracy: 0.9054 - val_loss: 0.4011 - val_accuracy: 0.8458\n",
      "Epoch 27/30\n",
      "188/188 - 11s - loss: 0.1951 - accuracy: 0.9027 - val_loss: 0.4521 - val_accuracy: 0.8308\n",
      "Epoch 28/30\n",
      "188/188 - 11s - loss: 0.1965 - accuracy: 0.9102 - val_loss: 0.4432 - val_accuracy: 0.8518\n",
      "Epoch 29/30\n",
      "188/188 - 11s - loss: 0.1902 - accuracy: 0.9105 - val_loss: 0.4361 - val_accuracy: 0.8473\n",
      "Epoch 30/30\n",
      "188/188 - 11s - loss: 0.2010 - accuracy: 0.9054 - val_loss: 0.4214 - val_accuracy: 0.8398\n",
      "HVLV_CNN_LSTM: Fold 10 : f1_macroscore: 0.8205\n",
      "HVLV_CNN_LSTM: Fold 10 : f1_weightedscore: 0.8407\n",
      "HVLV_CNN_LSTM: Fold 10 : acc: 0.8435\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and std of F1 MACRO is 0.8114 +- 0.0184\n",
      "Mean and std of F1 WEIGHTED is 0.8325 +- 0.0157\n",
      "Mean and std of accuracy is 0.8353 +- 0.0148\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f = 0\n",
    "f1_MacroNet = np.zeros([foldNum,]) \n",
    "f1_weightedNet = np.zeros([foldNum,])\n",
    "precisionNet = np.zeros([foldNum,])\n",
    "recallNet = np.zeros([foldNum,])\n",
    "accNet = np.zeros([foldNum,])\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=foldNum, random_state=111, shuffle=True)\n",
    "\n",
    "if arch == 'Plain_LSTM' or arch == 'BiLSTM':\n",
    "    feat_shape = features.shape\n",
    "    features = np.reshape(features, (feat_shape[0], feat_shape[1], feat_shape[2]*feat_shape[3]*feat_shape[4]))\n",
    "    print(\"entering if loop\")\n",
    "else:\n",
    "    pass\n",
    "\n",
    "for train, test in kfold.split(features, labels):\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    if arch == 'Plain_LSTM':\n",
    "        trainingFeatures = features[train,:,:]\n",
    "        testFeatures = features[test,:,:]\n",
    "        lstm = plain_lstm_model(optimizer, activation, num_units, dropout_rate, learn_rate)\n",
    "    elif arch == '2D-CNN_LSTM_Bashivan':\n",
    "        trainingFeatures = features[train,:,:,:,:]\n",
    "        testFeatures = features[test,:,:,:,:]\n",
    "        lstm = cnn2d_lstm_model_bashivan(optimizer, activation, kernel_size, padding, init_mode, \n",
    "                                         pool_size, stride_size, num_units, dense_layer_neuron_num,\n",
    "                                         nb_filters, class_num, dropout_rate, learn_rate)\n",
    "    elif arch == '2D-CNN_LSTM_Our':\n",
    "        trainingFeatures = features[train,:,:,:,:]\n",
    "        testFeatures = features[test,:,:,:,:]\n",
    "        lstm = cnn2d_lstm_model_our(optimizer, activation, kernel_size, padding, init_mode,\n",
    "                                    pool_size, stride_size, num_units, dense_layer_neuron_num,\n",
    "                                    nb_filters, class_num, dropout_rate, learn_rate)\n",
    "    elif arch == 'Conv_LSTM':\n",
    "        trainingFeatures = features[train,:,:,:,:]\n",
    "        testFeatures = features[test,:,:,:,:]\n",
    "        lstm = conv_lstm_model(optimizer, activation, kernel_size, padding, init_mode,\n",
    "                               pool_size, stride_size, num_units, dense_layer_neuron_num,\n",
    "                               nb_filters, class_num, dropout_rate, learn_rate)\n",
    "    elif arch == 'BiLSTM':\n",
    "        trainingFeatures = features[train,:,:]\n",
    "        testFeatures = features[test,:,:]\n",
    "        lstm = bilstm_model(optimizer, activation, kernel_size, padding, init_mode,\n",
    "                            pool_size, stride_size, num_units, dense_layer_neuron_num,\n",
    "                            nb_filters, class_num, dropout_rate, learn_rate)\n",
    "    \n",
    "    lstm.summary()\n",
    "    lstm.fit(trainingFeatures, labels_categorical[train,:], batch_size=batch_size,\n",
    "             epochs=epochs, verbose=2, validation_split=0.1)\n",
    "    predicted_labelsNet = lstm.predict_classes(testFeatures, verbose=0)\n",
    "    #predicted_probsNet = lstm.predict_proba(testFeatures,batch_size=1,verbose=0)\n",
    "    cm = confusion_matrix(labels[test,], predicted_labelsNet, labels=conf_mat_labels)\n",
    "    conf_mat = conf_mat+cm\n",
    "    \n",
    "    precisionNet[f] = precision_score(labels[test,], predicted_labelsNet, average='macro')\n",
    "    recallNet[f] = recall_score(labels[test,], predicted_labelsNet, average='macro')\n",
    "    f1_MacroNet[f] = f1_score(labels[test,], predicted_labelsNet, average='macro')\n",
    "    f1_weightedNet[f] = f1_score(labels[test,], predicted_labelsNet, average='weighted')\n",
    "    accNet[f] = accuracy_score(labels[test,], predicted_labelsNet)\n",
    "    print(experiment + '_CNN_LSTM: Fold %d : f1_macroscore: %.4f' % (f + 1, f1_MacroNet[f]))\n",
    "    print(experiment + '_CNN_LSTM: Fold %d : f1_weightedscore: %.4f' % (f + 1, f1_weightedNet[f]))\n",
    "    print(experiment + '_CNN_LSTM: Fold %d : acc: %.4f' % (f + 1, accNet[f]))\n",
    "    f += 1\n",
    "\n",
    "conf_mat /= conf_mat.sum(axis=1, keepdims = True)\n",
    "if experiment == 'Multi':\n",
    "    fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax = sns.heatmap(conf_mat, cmap='YlGnBu', annot = True, fmt='.4f', vmin=0, vmax=1, annot_kws = {'fontsize':12})\n",
    "ax.set_yticklabels(plot_labels, rotation = 0)\n",
    "ax.set_xticklabels(plot_labels, rotation = 0) \n",
    "\n",
    "\n",
    "ax.set_title(title)\n",
    "ax.get_figure().savefig(filename[:-4]+'_conf_mat'+'.png')\n",
    "plt.show()\n",
    "\n",
    "print('Mean and std of F1 MACRO is %.4f +- %.4f' % (np.mean(f1_MacroNet), np.std(f1_MacroNet)))\n",
    "print('Mean and std of F1 WEIGHTED is %.4f +- %.4f' % (np.mean(f1_weightedNet), np.std(f1_weightedNet)))\n",
    "print('Mean and std of accuracy is %.4f +- %.4f' % (np.mean(accNet), np.std(accNet)))\n",
    "\n",
    "# Save results\n",
    "sio.savemat(filename, {'precisionNet': precisionNet,'recallNet': recallNet, 'f1_MacroNet': f1_MacroNet,\n",
    "                       'f1_weightedNet':f1_weightedNet,'accNet':accNet, 'conf_mat':conf_mat,\n",
    "                       'experiment':experiment,'nb_filters':nb_filters,\n",
    "                       'kernel_size':kernel_size, 'pool_size':pool_size, 'stride_size':stride_size,\n",
    "                       'padding':padding, 'weight_decay':weight_decay,\n",
    "                       'dense_layer_neuron_num':dense_layer_neuron_num,'epochs':epochs,\n",
    "                       'lstm_num_units':num_units})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "EEG_CNN_LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
