{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from keras.layers import Conv1D, AveragePooling1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks  import EarlyStopping\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score,roc_auc_score, roc_curve, auc\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dense, Flatten, Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.callbacks  import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataPath = '../data/butter_feature_tensor_with_labels.mat'\n",
    "#dataPath = '../data/csp_features_full_with_full_labels.csv'\n",
    "dataPath = '../data/csp_feat_matrix_full_with_full_labels_3.mat'\n",
    "savePath = '../Results/CSP_3/'\n",
    "\n",
    "experiment = 'HALA_csp_1d_input_Full'\n",
    "\n",
    "filename = savePath+'CNN_1D_results_'+experiment+'.mat'\n",
    "plot_title = 'HA vs LA Classification for CSP Features - Full'\n",
    "\n",
    "nb_filters = [16, 32, 32, 64, 128]\n",
    "kernel_size = 3\n",
    "pool_size = 2\n",
    "stride_size = 2\n",
    "padding = 'same'\n",
    "weight_decay = 0.000001\n",
    "dense_layer_neuron_num = 128\n",
    "epochs = 30\n",
    "momentum =0.8\n",
    "\n",
    "matContent = sio.loadmat(dataPath)\n",
    "features = matContent['full_feat']\n",
    "labels = np.squeeze(matContent['full_hala_labels'])\n",
    "labels[labels < 0] = 0\n",
    "#labels[labels == 6] = 0\n",
    "#labels = labels.astype(int)\n",
    "\n",
    "#df = pd.read_csv(dataPath, header = None)\n",
    "#features = df.iloc[1:,:-2].to_numpy()\n",
    "#labels = df.iloc[1:,-1].to_numpy() # last but one column for PD vs NC\n",
    "\n",
    "#dict_hvlv = {1:0, 2:1, 3:0, 4:0, 5:1, 6:0} #HVLV labels mapping dictionary\n",
    "#labels = labels.map(dict_hvlv).to_numpy()\n",
    "#labels[labels == 1] = 0\n",
    "#labels[labels == 2] = 1\n",
    "#labels[labels == 3] = 1\n",
    "#labels[labels == 4] = 1\n",
    "#labels[labels == 5] = 1\n",
    "#labels[labels == 6] = 1\n",
    "#labels[labels < 0]=0\n",
    "#labels[labels == 6]=0\n",
    "\n",
    "# randomise the sample sequence\n",
    "rand_order = np.arange(features.shape[0])\n",
    "np.random.shuffle(rand_order)\n",
    "features = features[rand_order,]\n",
    "labels = np.squeeze(labels[rand_order,])\n",
    "class_num = np.size(np.unique(labels))\n",
    "labels_categorical = np_utils.to_categorical(labels, class_num)\n",
    "del matContent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14633, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(init_mode, activation, dropout_rate, optimizer, learn_rate):\n",
    "#def create_model(activation):\n",
    "  model = Sequential()\n",
    "  model.add(Conv1D(filters=nb_filters[0], kernel_size=kernel_size, padding=padding,\n",
    "                   activation=activation, input_shape=(X.shape[1], X.shape[2]), trainable=True))\n",
    "  model.add(AveragePooling1D(pool_size=pool_size, strides=stride_size, padding=padding))\n",
    "  model.add(Conv1D(filters=nb_filters[1], kernel_size=kernel_size, padding=padding,\n",
    "                   activation=activation, kernel_initializer=init_mode, trainable=True))\n",
    "  model.add(AveragePooling1D(pool_size=pool_size, strides=stride_size, padding=padding))\n",
    "  model.add(Conv1D(filters=nb_filters[2], kernel_size=kernel_size, padding=padding,\n",
    "                   activation=activation, kernel_initializer=init_mode, trainable=True))\n",
    "  model.add(AveragePooling1D(pool_size=pool_size, strides=stride_size, padding=padding))\n",
    "  # ####added by me#####\n",
    "  #model.add(Conv1D(filters=nb_filters[3], kernel_size=kernel_size, padding=padding, activation=activation,\n",
    "  #              kernel_initializer='he_normal'))\n",
    "  #model.add(AveragePooling1D(pool_size=pool_size, strides=stride_size, padding=padding))\n",
    "  #model.add(Conv1D(filters=nb_filters[4], kernel_size=kernel_size, padding=padding, activation=activation,\n",
    "  #              kernel_initializer='he_normal'))\n",
    "  #model.add(AveragePooling1D(pool_size=pool_size, strides=stride_size, padding=padding))\n",
    "  # ####added by me#####\n",
    "  model.add(Flatten())\n",
    "  model.add(BatchNormalization(epsilon=0.001))\n",
    "  model.add(Dense(dense_layer_neuron_num, kernel_initializer=init_mode, activation=activation))\n",
    "  model.add(Dropout(dropout_rate))\n",
    "  model.add(Dense(class_num))\n",
    "  model.add(Activation('softmax'))\n",
    "  #model.summary()\n",
    "  #model.load_weights('Gender_notClean_HIweights.hdf5')\n",
    "  #earlyStopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "  if optimizer == 'SGD':\n",
    "    opt = SGD(learning_rate=learn_rate / 10 ** epochs, momentum = momentum, decay = weight_decay, nesterov = True)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "  elif optimizer == 'Adam':\n",
    "    opt = Adam()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "  elif optimizer == 'RMSprop':\n",
    "    opt = RMSprop(learning_rate=learn_rate, epsilon=1e-07)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Gridsearch\n",
      "Best parameters: {'activation': 'relu', 'dropout_rate': 0.3, 'init_mode': 'he_uniform', 'learn_rate': 0.01, 'optimizer': 'RMSprop'}\n"
     ]
    }
   ],
   "source": [
    "cnn_model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "#batch_size = [16,32]\n",
    "#epochs = [5,10,15]\n",
    "#optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "#init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'he_normal', 'he_uniform']\n",
    "#activation = ['softmax', 'softsign', 'relu', 'tanh', 'sigmoid', 'linear']\n",
    "#dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "#learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "#momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "#neurons = [1, 5, 10, 15, 20, 25, 30]\n",
    "\n",
    "learn_rate = [0.001, 0.01, 0.1]\n",
    "optimizer = ['SGD', 'Adam','RMSprop']\n",
    "#momentum = [0.8,0.9]\n",
    "init_mode = ['he_normal','he_uniform']\n",
    "activation = ['relu','tanh']\n",
    "dropout_rate = [0.3,0.4,0.5]\n",
    "foldNum = 10\n",
    "\n",
    "p_grid = dict(init_mode=init_mode, dropout_rate=dropout_rate, activation=activation,\n",
    "              optimizer=optimizer, learn_rate=learn_rate)\n",
    "              #, momentum=momentum)\n",
    "grid = GridSearchCV(estimator=cnn_model, param_grid=p_grid,\n",
    "                    cv=foldNum, verbose=0)\n",
    "# Standerdize\n",
    "feat_shape = features.shape\n",
    "#features = np.reshape(features, (feat_shape[0], feat_shape[1]*feat_shape[2]))\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features)\n",
    "scaleFeatures = scaler.transform(features)\n",
    "scaleFeatures = np.reshape(scaleFeatures, (features.shape[0], 6, -1))\n",
    "\n",
    "print('Performing Gridsearch')\n",
    "X = scaleFeatures\n",
    "Y = labels_categorical\n",
    "grid_result = grid.fit(X,Y)\n",
    "best_params = grid_result.best_params_\n",
    "print('Best parameters:', best_params)\n",
    "estimator = create_model(init_mode=best_params.get('init_mode'), \n",
    "                         learn_rate=best_params.get('learn_rate'), \n",
    "                         optimizer=best_params.get('optimizer'), \n",
    "                         #momentum=best_params.get('momentum'), \n",
    "                         activation=best_params.get('activation'), \n",
    "                         dropout_rate=best_params.get('dropout_rate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1081\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3243 (Conv1D)         (None, 6, 16)             64        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3243 (Aver (None, 3, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3244 (Conv1D)         (None, 3, 32)             1568      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3244 (Aver (None, 2, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3245 (Conv1D)         (None, 2, 32)             3104      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3245 (Aver (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1081 (Flatten)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1081 (Ba (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_2162 (Dense)           (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dropout_1081 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2163 (Dense)           (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_1081 (Activation) (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 9,346\n",
      "Trainable params: 9,282\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "371/371 - 19s - loss: 0.3692 - accuracy: 0.8504 - val_loss: 0.4583 - val_accuracy: 0.8352\n",
      "Epoch 2/30\n",
      "371/371 - 2s - loss: 0.3085 - accuracy: 0.8659 - val_loss: 0.2977 - val_accuracy: 0.8603\n",
      "Epoch 3/30\n",
      "371/371 - 1s - loss: 0.2910 - accuracy: 0.8763 - val_loss: 0.3763 - val_accuracy: 0.8565\n",
      "Epoch 4/30\n",
      "371/371 - 2s - loss: 0.2763 - accuracy: 0.8799 - val_loss: 0.3179 - val_accuracy: 0.8679\n",
      "Epoch 5/30\n",
      "371/371 - 2s - loss: 0.2726 - accuracy: 0.8847 - val_loss: 0.3861 - val_accuracy: 0.8778\n",
      "Epoch 6/30\n",
      "371/371 - 2s - loss: 0.2671 - accuracy: 0.8858 - val_loss: 0.3025 - val_accuracy: 0.8838\n",
      "Epoch 7/30\n",
      "371/371 - 2s - loss: 0.2564 - accuracy: 0.8901 - val_loss: 0.3641 - val_accuracy: 0.8573\n",
      "Epoch 8/30\n",
      "371/371 - 2s - loss: 0.2549 - accuracy: 0.8910 - val_loss: 0.2642 - val_accuracy: 0.8945\n",
      "Epoch 9/30\n",
      "371/371 - 2s - loss: 0.2507 - accuracy: 0.8927 - val_loss: 0.2782 - val_accuracy: 0.8869\n",
      "Epoch 10/30\n",
      "371/371 - 2s - loss: 0.2579 - accuracy: 0.8920 - val_loss: 0.2696 - val_accuracy: 0.8967\n",
      "Epoch 11/30\n",
      "371/371 - 2s - loss: 0.2422 - accuracy: 0.8981 - val_loss: 0.3616 - val_accuracy: 0.8109\n",
      "Epoch 12/30\n",
      "371/371 - 3s - loss: 0.2482 - accuracy: 0.8952 - val_loss: 0.2700 - val_accuracy: 0.8952\n",
      "Epoch 13/30\n",
      "371/371 - 2s - loss: 0.2460 - accuracy: 0.8961 - val_loss: 0.3378 - val_accuracy: 0.8709\n",
      "Epoch 14/30\n",
      "371/371 - 2s - loss: 0.2535 - accuracy: 0.8944 - val_loss: 0.2910 - val_accuracy: 0.8853\n",
      "Epoch 15/30\n",
      "371/371 - 2s - loss: 0.2467 - accuracy: 0.8958 - val_loss: 0.2660 - val_accuracy: 0.8861\n",
      "Epoch 16/30\n",
      "371/371 - 1s - loss: 0.2478 - accuracy: 0.9000 - val_loss: 0.3777 - val_accuracy: 0.8504\n",
      "Epoch 17/30\n",
      "371/371 - 2s - loss: 0.2509 - accuracy: 0.8954 - val_loss: 0.3264 - val_accuracy: 0.8793\n",
      "Epoch 18/30\n",
      "371/371 - 2s - loss: 0.2494 - accuracy: 0.8947 - val_loss: 0.2614 - val_accuracy: 0.9028\n",
      "Epoch 19/30\n",
      "371/371 - 2s - loss: 0.2429 - accuracy: 0.8991 - val_loss: 0.3522 - val_accuracy: 0.8914\n",
      "Epoch 20/30\n",
      "371/371 - 2s - loss: 0.2511 - accuracy: 0.8947 - val_loss: 0.4063 - val_accuracy: 0.8565\n",
      "Epoch 21/30\n",
      "371/371 - 2s - loss: 0.2428 - accuracy: 0.9004 - val_loss: 0.2718 - val_accuracy: 0.8876\n",
      "Epoch 22/30\n",
      "371/371 - 2s - loss: 0.2521 - accuracy: 0.8979 - val_loss: 0.2714 - val_accuracy: 0.9043\n",
      "Epoch 23/30\n",
      "371/371 - 2s - loss: 0.2590 - accuracy: 0.8991 - val_loss: 0.3379 - val_accuracy: 0.8884\n",
      "Epoch 24/30\n",
      "371/371 - 2s - loss: 0.2470 - accuracy: 0.8988 - val_loss: 0.2741 - val_accuracy: 0.9036\n",
      "Epoch 25/30\n",
      "371/371 - 1s - loss: 0.2480 - accuracy: 0.8998 - val_loss: 0.2581 - val_accuracy: 0.9043\n",
      "Epoch 26/30\n",
      "371/371 - 2s - loss: 0.2493 - accuracy: 0.9020 - val_loss: 0.2661 - val_accuracy: 0.8899\n",
      "Epoch 27/30\n",
      "371/371 - 1s - loss: 0.2455 - accuracy: 0.8989 - val_loss: 0.2788 - val_accuracy: 0.8694\n",
      "Epoch 28/30\n",
      "371/371 - 1s - loss: 0.2562 - accuracy: 0.8950 - val_loss: 0.3882 - val_accuracy: 0.8694\n",
      "Epoch 29/30\n",
      "371/371 - 1s - loss: 0.2468 - accuracy: 0.9015 - val_loss: 0.2792 - val_accuracy: 0.8983\n",
      "Epoch 30/30\n",
      "371/371 - 1s - loss: 0.2508 - accuracy: 0.9035 - val_loss: 0.3023 - val_accuracy: 0.8793\n",
      "WARNING:tensorflow:From <ipython-input-9-04aa081ccf5a>:33: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "WARNING:tensorflow:From <ipython-input-9-04aa081ccf5a>:34: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use `model.predict()` instead.\n",
      "HALA_csp_1d_input_Full_CNN: Fold 1 : f1_macroscore: 0.6970\n",
      "HALA_csp_1d_input_Full_CNN: Fold 1 : f1_weightedscore: 0.8549\n",
      "HALA_csp_1d_input_Full_CNN: Fold 1 : acc: 0.8791\n",
      "Model: \"sequential_1081\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3243 (Conv1D)         (None, 6, 16)             64        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3243 (Aver (None, 3, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3244 (Conv1D)         (None, 3, 32)             1568      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3244 (Aver (None, 2, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3245 (Conv1D)         (None, 2, 32)             3104      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3245 (Aver (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1081 (Flatten)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1081 (Ba (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_2162 (Dense)           (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dropout_1081 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2163 (Dense)           (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_1081 (Activation) (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 9,346\n",
      "Trainable params: 9,282\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "371/371 - 2s - loss: 0.2493 - accuracy: 0.9034 - val_loss: 0.4567 - val_accuracy: 0.8504\n",
      "Epoch 2/30\n",
      "371/371 - 2s - loss: 0.2553 - accuracy: 0.9009 - val_loss: 0.2633 - val_accuracy: 0.8967\n",
      "Epoch 3/30\n",
      "371/371 - 2s - loss: 0.2562 - accuracy: 0.8992 - val_loss: 0.2799 - val_accuracy: 0.8815\n",
      "Epoch 4/30\n",
      "371/371 - 2s - loss: 0.2464 - accuracy: 0.9030 - val_loss: 0.2558 - val_accuracy: 0.9058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "371/371 - 1s - loss: 0.2515 - accuracy: 0.9017 - val_loss: 0.2520 - val_accuracy: 0.9127\n",
      "Epoch 6/30\n",
      "371/371 - 2s - loss: 0.2595 - accuracy: 0.9017 - val_loss: 0.2922 - val_accuracy: 0.8990\n",
      "Epoch 7/30\n",
      "371/371 - 2s - loss: 0.2493 - accuracy: 0.9077 - val_loss: 0.3641 - val_accuracy: 0.8656\n",
      "Epoch 8/30\n",
      "371/371 - 1s - loss: 0.2542 - accuracy: 0.9044 - val_loss: 0.8565 - val_accuracy: 0.8474\n",
      "Epoch 9/30\n",
      "371/371 - 1s - loss: 0.2548 - accuracy: 0.9077 - val_loss: 0.2563 - val_accuracy: 0.9127\n",
      "Epoch 10/30\n",
      "371/371 - 1s - loss: 0.2584 - accuracy: 0.9019 - val_loss: 0.3392 - val_accuracy: 0.8550\n",
      "Epoch 11/30\n",
      "371/371 - 2s - loss: 0.2625 - accuracy: 0.9035 - val_loss: 0.3222 - val_accuracy: 0.8709\n",
      "Epoch 12/30\n",
      "371/371 - 2s - loss: 0.2566 - accuracy: 0.9018 - val_loss: 0.2638 - val_accuracy: 0.9165\n",
      "Epoch 13/30\n",
      "371/371 - 1s - loss: 0.2593 - accuracy: 0.8998 - val_loss: 0.3026 - val_accuracy: 0.8603\n",
      "Epoch 14/30\n",
      "371/371 - 1s - loss: 0.2549 - accuracy: 0.9025 - val_loss: 0.3840 - val_accuracy: 0.8671\n",
      "Epoch 15/30\n",
      "371/371 - 1s - loss: 0.2542 - accuracy: 0.9028 - val_loss: 0.2692 - val_accuracy: 0.9127\n",
      "Epoch 16/30\n",
      "371/371 - 1s - loss: 0.2612 - accuracy: 0.9006 - val_loss: 0.2878 - val_accuracy: 0.8983\n",
      "Epoch 17/30\n",
      "371/371 - 1s - loss: 0.2633 - accuracy: 0.8994 - val_loss: 0.2673 - val_accuracy: 0.9112\n",
      "Epoch 18/30\n",
      "371/371 - 1s - loss: 0.2639 - accuracy: 0.9012 - val_loss: 0.2640 - val_accuracy: 0.8899\n",
      "Epoch 19/30\n",
      "371/371 - 1s - loss: 0.2593 - accuracy: 0.9036 - val_loss: 0.3094 - val_accuracy: 0.9089\n",
      "Epoch 20/30\n",
      "371/371 - 1s - loss: 0.2636 - accuracy: 0.9027 - val_loss: 0.2473 - val_accuracy: 0.9188\n",
      "Epoch 21/30\n",
      "371/371 - 1s - loss: 0.2564 - accuracy: 0.9005 - val_loss: 0.3464 - val_accuracy: 0.9028\n",
      "Epoch 22/30\n",
      "371/371 - 1s - loss: 0.2568 - accuracy: 0.9029 - val_loss: 0.3732 - val_accuracy: 0.8451\n",
      "Epoch 23/30\n",
      "371/371 - 1s - loss: 0.2620 - accuracy: 0.9025 - val_loss: 0.2633 - val_accuracy: 0.9005\n",
      "Epoch 24/30\n",
      "371/371 - 1s - loss: 0.2590 - accuracy: 0.9064 - val_loss: 0.2870 - val_accuracy: 0.9089\n",
      "Epoch 25/30\n",
      "371/371 - 1s - loss: 0.2445 - accuracy: 0.9052 - val_loss: 0.2615 - val_accuracy: 0.9142\n",
      "Epoch 26/30\n",
      "371/371 - 1s - loss: 0.2532 - accuracy: 0.9076 - val_loss: 0.2636 - val_accuracy: 0.9112\n",
      "Epoch 27/30\n",
      "371/371 - 1s - loss: 0.2518 - accuracy: 0.9058 - val_loss: 0.2805 - val_accuracy: 0.9203\n",
      "Epoch 28/30\n",
      "371/371 - 1s - loss: 0.2443 - accuracy: 0.9077 - val_loss: 0.5479 - val_accuracy: 0.8497\n",
      "Epoch 29/30\n",
      "371/371 - 1s - loss: 0.2503 - accuracy: 0.9094 - val_loss: 0.3441 - val_accuracy: 0.9119\n",
      "Epoch 30/30\n",
      "371/371 - 1s - loss: 0.2548 - accuracy: 0.9073 - val_loss: 0.2768 - val_accuracy: 0.9104\n",
      "HALA_csp_1d_input_Full_CNN: Fold 2 : f1_macroscore: 0.8500\n",
      "HALA_csp_1d_input_Full_CNN: Fold 2 : f1_weightedscore: 0.9172\n",
      "HALA_csp_1d_input_Full_CNN: Fold 2 : acc: 0.9167\n",
      "Model: \"sequential_1081\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3243 (Conv1D)         (None, 6, 16)             64        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3243 (Aver (None, 3, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3244 (Conv1D)         (None, 3, 32)             1568      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3244 (Aver (None, 2, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3245 (Conv1D)         (None, 2, 32)             3104      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3245 (Aver (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1081 (Flatten)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1081 (Ba (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_2162 (Dense)           (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dropout_1081 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2163 (Dense)           (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_1081 (Activation) (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 9,346\n",
      "Trainable params: 9,282\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "371/371 - 1s - loss: 0.2522 - accuracy: 0.9091 - val_loss: 0.2941 - val_accuracy: 0.9036\n",
      "Epoch 2/30\n",
      "371/371 - 1s - loss: 0.2417 - accuracy: 0.9096 - val_loss: 0.3624 - val_accuracy: 0.9119\n",
      "Epoch 3/30\n",
      "371/371 - 1s - loss: 0.2486 - accuracy: 0.9130 - val_loss: 0.4145 - val_accuracy: 0.8891\n",
      "Epoch 4/30\n",
      "371/371 - 1s - loss: 0.2445 - accuracy: 0.9083 - val_loss: 0.3342 - val_accuracy: 0.8709\n",
      "Epoch 5/30\n",
      "371/371 - 1s - loss: 0.2509 - accuracy: 0.9083 - val_loss: 0.2750 - val_accuracy: 0.9157\n",
      "Epoch 6/30\n",
      "371/371 - 1s - loss: 0.2462 - accuracy: 0.9074 - val_loss: 0.3409 - val_accuracy: 0.9127\n",
      "Epoch 7/30\n",
      "371/371 - 1s - loss: 0.2416 - accuracy: 0.9105 - val_loss: 0.3677 - val_accuracy: 0.8724\n",
      "Epoch 8/30\n",
      "371/371 - 1s - loss: 0.2481 - accuracy: 0.9102 - val_loss: 0.4382 - val_accuracy: 0.8724\n",
      "Epoch 9/30\n",
      "371/371 - 1s - loss: 0.2476 - accuracy: 0.9113 - val_loss: 0.3282 - val_accuracy: 0.8891\n",
      "Epoch 10/30\n",
      "371/371 - 1s - loss: 0.2395 - accuracy: 0.9119 - val_loss: 0.3513 - val_accuracy: 0.9096\n",
      "Epoch 11/30\n",
      "371/371 - 1s - loss: 0.2412 - accuracy: 0.9089 - val_loss: 0.3574 - val_accuracy: 0.8990\n",
      "Epoch 12/30\n",
      "371/371 - 1s - loss: 0.2485 - accuracy: 0.9123 - val_loss: 0.3709 - val_accuracy: 0.8929\n",
      "Epoch 13/30\n",
      "371/371 - 1s - loss: 0.2491 - accuracy: 0.9103 - val_loss: 0.3331 - val_accuracy: 0.9005\n",
      "Epoch 14/30\n",
      "371/371 - 1s - loss: 0.2462 - accuracy: 0.9119 - val_loss: 0.3639 - val_accuracy: 0.9150\n",
      "Epoch 15/30\n",
      "371/371 - 1s - loss: 0.2360 - accuracy: 0.9133 - val_loss: 0.4864 - val_accuracy: 0.8952\n",
      "Epoch 16/30\n",
      "371/371 - 1s - loss: 0.2438 - accuracy: 0.9140 - val_loss: 0.3666 - val_accuracy: 0.9074\n",
      "Epoch 17/30\n",
      "371/371 - 1s - loss: 0.2431 - accuracy: 0.9079 - val_loss: 0.3444 - val_accuracy: 0.9074\n",
      "Epoch 18/30\n",
      "371/371 - 1s - loss: 0.2446 - accuracy: 0.9134 - val_loss: 0.3127 - val_accuracy: 0.9089\n",
      "Epoch 19/30\n",
      "371/371 - 1s - loss: 0.2456 - accuracy: 0.9122 - val_loss: 0.3538 - val_accuracy: 0.9051\n",
      "Epoch 20/30\n",
      "371/371 - 1s - loss: 0.2410 - accuracy: 0.9102 - val_loss: 0.2883 - val_accuracy: 0.9021\n",
      "Epoch 21/30\n",
      "371/371 - 1s - loss: 0.2427 - accuracy: 0.9133 - val_loss: 0.3273 - val_accuracy: 0.9112\n",
      "Epoch 22/30\n",
      "371/371 - 1s - loss: 0.2368 - accuracy: 0.9133 - val_loss: 0.3903 - val_accuracy: 0.8899\n",
      "Epoch 23/30\n",
      "371/371 - 1s - loss: 0.2269 - accuracy: 0.9167 - val_loss: 0.3094 - val_accuracy: 0.9089\n",
      "Epoch 24/30\n",
      "371/371 - 1s - loss: 0.2359 - accuracy: 0.9135 - val_loss: 0.3641 - val_accuracy: 0.8945\n",
      "Epoch 25/30\n",
      "371/371 - 1s - loss: 0.2393 - accuracy: 0.9106 - val_loss: 0.4953 - val_accuracy: 0.8732\n",
      "Epoch 26/30\n",
      "371/371 - 1s - loss: 0.2351 - accuracy: 0.9143 - val_loss: 0.3617 - val_accuracy: 0.8922\n",
      "Epoch 27/30\n",
      "371/371 - 1s - loss: 0.2339 - accuracy: 0.9123 - val_loss: 0.3216 - val_accuracy: 0.9172\n",
      "Epoch 28/30\n",
      "371/371 - 1s - loss: 0.2450 - accuracy: 0.9142 - val_loss: 0.3950 - val_accuracy: 0.8914\n",
      "Epoch 29/30\n",
      "371/371 - 1s - loss: 0.2453 - accuracy: 0.9140 - val_loss: 0.4530 - val_accuracy: 0.8451\n",
      "Epoch 30/30\n",
      "371/371 - 1s - loss: 0.2387 - accuracy: 0.9148 - val_loss: 0.3563 - val_accuracy: 0.8899\n",
      "HALA_csp_1d_input_Full_CNN: Fold 3 : f1_macroscore: 0.8383\n",
      "HALA_csp_1d_input_Full_CNN: Fold 3 : f1_weightedscore: 0.9079\n",
      "HALA_csp_1d_input_Full_CNN: Fold 3 : acc: 0.9044\n",
      "Model: \"sequential_1081\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3243 (Conv1D)         (None, 6, 16)             64        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3243 (Aver (None, 3, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3244 (Conv1D)         (None, 3, 32)             1568      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3244 (Aver (None, 2, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3245 (Conv1D)         (None, 2, 32)             3104      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3245 (Aver (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1081 (Flatten)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1081 (Ba (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_2162 (Dense)           (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dropout_1081 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2163 (Dense)           (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_1081 (Activation) (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 9,346\n",
      "Trainable params: 9,282\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371/371 - 13s - loss: 0.2510 - accuracy: 0.9117 - val_loss: 0.3384 - val_accuracy: 0.9119\n",
      "Epoch 2/30\n",
      "371/371 - 1s - loss: 0.2443 - accuracy: 0.9153 - val_loss: 0.3319 - val_accuracy: 0.9134\n",
      "Epoch 3/30\n",
      "371/371 - 1s - loss: 0.2449 - accuracy: 0.9132 - val_loss: 0.3193 - val_accuracy: 0.9089\n",
      "Epoch 4/30\n",
      "371/371 - 1s - loss: 0.2449 - accuracy: 0.9126 - val_loss: 0.3095 - val_accuracy: 0.9051\n",
      "Epoch 5/30\n",
      "371/371 - 1s - loss: 0.2502 - accuracy: 0.9142 - val_loss: 0.2922 - val_accuracy: 0.9112\n",
      "Epoch 6/30\n",
      "371/371 - 1s - loss: 0.2527 - accuracy: 0.9131 - val_loss: 0.3390 - val_accuracy: 0.9089\n",
      "Epoch 7/30\n",
      "371/371 - 1s - loss: 0.2665 - accuracy: 0.9098 - val_loss: 0.4328 - val_accuracy: 0.8952\n",
      "Epoch 8/30\n",
      "371/371 - 1s - loss: 0.2479 - accuracy: 0.9141 - val_loss: 0.5370 - val_accuracy: 0.8671\n",
      "Epoch 9/30\n",
      "371/371 - 1s - loss: 0.2574 - accuracy: 0.9131 - val_loss: 0.3457 - val_accuracy: 0.9112\n",
      "Epoch 10/30\n",
      "371/371 - 1s - loss: 0.2512 - accuracy: 0.9145 - val_loss: 0.3413 - val_accuracy: 0.9119\n",
      "Epoch 11/30\n",
      "371/371 - 1s - loss: 0.2510 - accuracy: 0.9104 - val_loss: 0.3098 - val_accuracy: 0.9074\n",
      "Epoch 12/30\n",
      "371/371 - 1s - loss: 0.2392 - accuracy: 0.9143 - val_loss: 0.3715 - val_accuracy: 0.8724\n",
      "Epoch 13/30\n",
      "371/371 - 1s - loss: 0.2461 - accuracy: 0.9116 - val_loss: 0.3131 - val_accuracy: 0.9089\n",
      "Epoch 14/30\n",
      "371/371 - 1s - loss: 0.2503 - accuracy: 0.9122 - val_loss: 0.3253 - val_accuracy: 0.9188\n",
      "Epoch 15/30\n",
      "371/371 - 1s - loss: 0.2469 - accuracy: 0.9126 - val_loss: 0.3747 - val_accuracy: 0.9089\n",
      "Epoch 16/30\n",
      "371/371 - 1s - loss: 0.2486 - accuracy: 0.9126 - val_loss: 0.2739 - val_accuracy: 0.8998\n",
      "Epoch 17/30\n",
      "371/371 - 1s - loss: 0.2500 - accuracy: 0.9118 - val_loss: 0.2961 - val_accuracy: 0.9180\n",
      "Epoch 18/30\n",
      "371/371 - 1s - loss: 0.2383 - accuracy: 0.9148 - val_loss: 0.3235 - val_accuracy: 0.9081\n",
      "Epoch 19/30\n",
      "371/371 - 1s - loss: 0.2380 - accuracy: 0.9155 - val_loss: 0.4196 - val_accuracy: 0.8937\n",
      "Epoch 20/30\n",
      "371/371 - 1s - loss: 0.2434 - accuracy: 0.9141 - val_loss: 0.3191 - val_accuracy: 0.8952\n",
      "Epoch 21/30\n",
      "371/371 - 1s - loss: 0.2470 - accuracy: 0.9144 - val_loss: 0.3233 - val_accuracy: 0.9066\n",
      "Epoch 22/30\n",
      "371/371 - 1s - loss: 0.2388 - accuracy: 0.9169 - val_loss: 0.3423 - val_accuracy: 0.9058\n",
      "Epoch 23/30\n",
      "371/371 - 1s - loss: 0.2461 - accuracy: 0.9128 - val_loss: 0.3801 - val_accuracy: 0.8747\n",
      "Epoch 24/30\n",
      "371/371 - 1s - loss: 0.2477 - accuracy: 0.9157 - val_loss: 0.2949 - val_accuracy: 0.9036\n",
      "Epoch 25/30\n",
      "371/371 - 1s - loss: 0.2435 - accuracy: 0.9128 - val_loss: 0.3040 - val_accuracy: 0.9165\n",
      "Epoch 26/30\n",
      "371/371 - 1s - loss: 0.2430 - accuracy: 0.9135 - val_loss: 0.3967 - val_accuracy: 0.8838\n",
      "Epoch 27/30\n",
      "371/371 - 1s - loss: 0.2396 - accuracy: 0.9145 - val_loss: 0.4949 - val_accuracy: 0.8436\n",
      "Epoch 28/30\n",
      "371/371 - 1s - loss: 0.2423 - accuracy: 0.9157 - val_loss: 0.3166 - val_accuracy: 0.9203\n",
      "Epoch 29/30\n",
      "371/371 - 1s - loss: 0.2322 - accuracy: 0.9166 - val_loss: 0.5653 - val_accuracy: 0.9081\n",
      "Epoch 30/30\n",
      "371/371 - 1s - loss: 0.2422 - accuracy: 0.9154 - val_loss: 0.3057 - val_accuracy: 0.9051\n",
      "HALA_csp_1d_input_Full_CNN: Fold 4 : f1_macroscore: 0.8594\n",
      "HALA_csp_1d_input_Full_CNN: Fold 4 : f1_weightedscore: 0.9230\n",
      "HALA_csp_1d_input_Full_CNN: Fold 4 : acc: 0.9228\n",
      "Model: \"sequential_1081\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3243 (Conv1D)         (None, 6, 16)             64        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3243 (Aver (None, 3, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3244 (Conv1D)         (None, 3, 32)             1568      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3244 (Aver (None, 2, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3245 (Conv1D)         (None, 2, 32)             3104      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3245 (Aver (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1081 (Flatten)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1081 (Ba (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_2162 (Dense)           (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dropout_1081 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2163 (Dense)           (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_1081 (Activation) (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 9,346\n",
      "Trainable params: 9,282\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "371/371 - 1s - loss: 0.2386 - accuracy: 0.9155 - val_loss: 0.3536 - val_accuracy: 0.9043\n",
      "Epoch 2/30\n",
      "371/371 - 1s - loss: 0.2398 - accuracy: 0.9200 - val_loss: 0.3150 - val_accuracy: 0.9180\n",
      "Epoch 3/30\n",
      "371/371 - 1s - loss: 0.2355 - accuracy: 0.9162 - val_loss: 0.4705 - val_accuracy: 0.8762\n",
      "Epoch 4/30\n",
      "371/371 - 1s - loss: 0.2407 - accuracy: 0.9096 - val_loss: 0.3870 - val_accuracy: 0.8413\n",
      "Epoch 5/30\n",
      "371/371 - 1s - loss: 0.2356 - accuracy: 0.9157 - val_loss: 1.2464 - val_accuracy: 0.8459\n",
      "Epoch 6/30\n",
      "371/371 - 1s - loss: 0.2398 - accuracy: 0.9161 - val_loss: 0.4946 - val_accuracy: 0.8724\n",
      "Epoch 7/30\n",
      "371/371 - 1s - loss: 0.2293 - accuracy: 0.9156 - val_loss: 0.3375 - val_accuracy: 0.9074\n",
      "Epoch 8/30\n",
      "371/371 - 1s - loss: 0.2404 - accuracy: 0.9155 - val_loss: 0.3100 - val_accuracy: 0.9157\n",
      "Epoch 9/30\n",
      "371/371 - 1s - loss: 0.2339 - accuracy: 0.9181 - val_loss: 0.4042 - val_accuracy: 0.8778\n",
      "Epoch 10/30\n",
      "371/371 - 1s - loss: 0.2409 - accuracy: 0.9175 - val_loss: 0.3069 - val_accuracy: 0.9165\n",
      "Epoch 11/30\n",
      "371/371 - 1s - loss: 0.2387 - accuracy: 0.9136 - val_loss: 0.3095 - val_accuracy: 0.9081\n",
      "Epoch 12/30\n",
      "371/371 - 1s - loss: 0.2330 - accuracy: 0.9161 - val_loss: 0.3247 - val_accuracy: 0.8960\n",
      "Epoch 13/30\n",
      "371/371 - 1s - loss: 0.2327 - accuracy: 0.9166 - val_loss: 0.3399 - val_accuracy: 0.8778\n",
      "Epoch 14/30\n",
      "371/371 - 1s - loss: 0.2354 - accuracy: 0.9147 - val_loss: 0.4552 - val_accuracy: 0.8102\n",
      "Epoch 15/30\n",
      "371/371 - 1s - loss: 0.2353 - accuracy: 0.9194 - val_loss: 0.4172 - val_accuracy: 0.8246\n",
      "Epoch 16/30\n",
      "371/371 - 1s - loss: 0.2372 - accuracy: 0.9173 - val_loss: 0.2898 - val_accuracy: 0.9203\n",
      "Epoch 17/30\n",
      "371/371 - 1s - loss: 0.2372 - accuracy: 0.9161 - val_loss: 0.3128 - val_accuracy: 0.9036\n",
      "Epoch 18/30\n",
      "371/371 - 1s - loss: 0.2317 - accuracy: 0.9171 - val_loss: 0.3339 - val_accuracy: 0.9172\n",
      "Epoch 19/30\n",
      "371/371 - 1s - loss: 0.2266 - accuracy: 0.9217 - val_loss: 0.3101 - val_accuracy: 0.9005\n",
      "Epoch 20/30\n",
      "371/371 - 1s - loss: 0.2334 - accuracy: 0.9193 - val_loss: 0.2901 - val_accuracy: 0.9195\n",
      "Epoch 21/30\n",
      "371/371 - 1s - loss: 0.2313 - accuracy: 0.9185 - val_loss: 0.3225 - val_accuracy: 0.9195\n",
      "Epoch 22/30\n",
      "371/371 - 1s - loss: 0.2360 - accuracy: 0.9178 - val_loss: 0.4470 - val_accuracy: 0.8770\n",
      "Epoch 23/30\n",
      "371/371 - 1s - loss: 0.2268 - accuracy: 0.9177 - val_loss: 0.2950 - val_accuracy: 0.9248\n",
      "Epoch 24/30\n",
      "371/371 - 1s - loss: 0.2303 - accuracy: 0.9159 - val_loss: 0.3332 - val_accuracy: 0.9188\n",
      "Epoch 25/30\n",
      "371/371 - 1s - loss: 0.2249 - accuracy: 0.9183 - val_loss: 0.2917 - val_accuracy: 0.9203\n",
      "Epoch 26/30\n",
      "371/371 - 1s - loss: 0.2272 - accuracy: 0.9193 - val_loss: 0.3126 - val_accuracy: 0.8853\n",
      "Epoch 27/30\n",
      "371/371 - 1s - loss: 0.2295 - accuracy: 0.9171 - val_loss: 0.3895 - val_accuracy: 0.8755\n",
      "Epoch 28/30\n",
      "371/371 - 1s - loss: 0.2335 - accuracy: 0.9193 - val_loss: 0.3182 - val_accuracy: 0.9165\n",
      "Epoch 29/30\n",
      "371/371 - 1s - loss: 0.2306 - accuracy: 0.9183 - val_loss: 0.3019 - val_accuracy: 0.9089\n",
      "Epoch 30/30\n",
      "371/371 - 1s - loss: 0.2316 - accuracy: 0.9175 - val_loss: 0.3084 - val_accuracy: 0.8952\n",
      "HALA_csp_1d_input_Full_CNN: Fold 5 : f1_macroscore: 0.8424\n",
      "HALA_csp_1d_input_Full_CNN: Fold 5 : f1_weightedscore: 0.9093\n",
      "HALA_csp_1d_input_Full_CNN: Fold 5 : acc: 0.9050\n",
      "Model: \"sequential_1081\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3243 (Conv1D)         (None, 6, 16)             64        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3243 (Aver (None, 3, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3244 (Conv1D)         (None, 3, 32)             1568      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3244 (Aver (None, 2, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3245 (Conv1D)         (None, 2, 32)             3104      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3245 (Aver (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1081 (Flatten)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1081 (Ba (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_2162 (Dense)           (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dropout_1081 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2163 (Dense)           (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_1081 (Activation) (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 9,346\n",
      "Trainable params: 9,282\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371/371 - 1s - loss: 0.2343 - accuracy: 0.9122 - val_loss: 0.3590 - val_accuracy: 0.8975\n",
      "Epoch 2/30\n",
      "371/371 - 1s - loss: 0.2357 - accuracy: 0.9168 - val_loss: 0.5383 - val_accuracy: 0.8208\n",
      "Epoch 3/30\n",
      "371/371 - 1s - loss: 0.2203 - accuracy: 0.9183 - val_loss: 0.3141 - val_accuracy: 0.8853\n",
      "Epoch 4/30\n",
      "371/371 - 1s - loss: 0.2276 - accuracy: 0.9183 - val_loss: 0.3608 - val_accuracy: 0.9172\n",
      "Epoch 5/30\n",
      "371/371 - 1s - loss: 0.2290 - accuracy: 0.9160 - val_loss: 0.3289 - val_accuracy: 0.9157\n",
      "Epoch 6/30\n",
      "371/371 - 1s - loss: 0.2247 - accuracy: 0.9162 - val_loss: 0.3266 - val_accuracy: 0.8960\n",
      "Epoch 7/30\n",
      "371/371 - 1s - loss: 0.2228 - accuracy: 0.9177 - val_loss: 0.3652 - val_accuracy: 0.9081\n",
      "Epoch 8/30\n",
      "371/371 - 1s - loss: 0.2193 - accuracy: 0.9198 - val_loss: 0.3894 - val_accuracy: 0.9134\n",
      "Epoch 9/30\n",
      "371/371 - 1s - loss: 0.2249 - accuracy: 0.9162 - val_loss: 0.4925 - val_accuracy: 0.8770\n",
      "Epoch 10/30\n",
      "371/371 - 1s - loss: 0.2237 - accuracy: 0.9204 - val_loss: 0.2653 - val_accuracy: 0.9074\n",
      "Epoch 11/30\n",
      "371/371 - 1s - loss: 0.2241 - accuracy: 0.9179 - val_loss: 0.3088 - val_accuracy: 0.8709\n",
      "Epoch 12/30\n",
      "371/371 - 1s - loss: 0.2115 - accuracy: 0.9197 - val_loss: 0.3337 - val_accuracy: 0.9188\n",
      "Epoch 13/30\n",
      "371/371 - 1s - loss: 0.2226 - accuracy: 0.9195 - val_loss: 0.4030 - val_accuracy: 0.9096\n",
      "Epoch 14/30\n",
      "371/371 - 1s - loss: 0.2253 - accuracy: 0.9186 - val_loss: 0.2923 - val_accuracy: 0.9180\n",
      "Epoch 15/30\n",
      "371/371 - 1s - loss: 0.2231 - accuracy: 0.9156 - val_loss: 0.2589 - val_accuracy: 0.9081\n",
      "Epoch 16/30\n",
      "371/371 - 1s - loss: 0.2171 - accuracy: 0.9211 - val_loss: 0.2505 - val_accuracy: 0.9180\n",
      "Epoch 17/30\n",
      "371/371 - 1s - loss: 0.2157 - accuracy: 0.9242 - val_loss: 0.4753 - val_accuracy: 0.8656\n",
      "Epoch 18/30\n",
      "371/371 - 1s - loss: 0.2183 - accuracy: 0.9212 - val_loss: 0.8235 - val_accuracy: 0.8489\n",
      "Epoch 19/30\n",
      "371/371 - 1s - loss: 0.2270 - accuracy: 0.9174 - val_loss: 0.3411 - val_accuracy: 0.8990\n",
      "Epoch 20/30\n",
      "371/371 - 1s - loss: 0.2178 - accuracy: 0.9166 - val_loss: 0.2759 - val_accuracy: 0.9127\n",
      "Epoch 21/30\n",
      "371/371 - 1s - loss: 0.2076 - accuracy: 0.9192 - val_loss: 0.3754 - val_accuracy: 0.9096\n",
      "Epoch 22/30\n",
      "371/371 - 1s - loss: 0.2225 - accuracy: 0.9200 - val_loss: 0.2908 - val_accuracy: 0.9180\n",
      "Epoch 23/30\n",
      "371/371 - 1s - loss: 0.2092 - accuracy: 0.9213 - val_loss: 0.4219 - val_accuracy: 0.8998\n",
      "Epoch 24/30\n",
      "371/371 - 1s - loss: 0.2165 - accuracy: 0.9203 - val_loss: 0.3465 - val_accuracy: 0.9180\n",
      "Epoch 25/30\n",
      "371/371 - 1s - loss: 0.2141 - accuracy: 0.9208 - val_loss: 0.3349 - val_accuracy: 0.9134\n",
      "Epoch 26/30\n",
      "371/371 - 1s - loss: 0.2219 - accuracy: 0.9200 - val_loss: 0.5372 - val_accuracy: 0.9028\n",
      "Epoch 27/30\n",
      "371/371 - 1s - loss: 0.2110 - accuracy: 0.9223 - val_loss: 0.2496 - val_accuracy: 0.9089\n",
      "Epoch 28/30\n",
      "371/371 - 1s - loss: 0.2056 - accuracy: 0.9210 - val_loss: 0.2693 - val_accuracy: 0.9081\n",
      "Epoch 29/30\n",
      "371/371 - 1s - loss: 0.2082 - accuracy: 0.9179 - val_loss: 0.5267 - val_accuracy: 0.8709\n",
      "Epoch 30/30\n",
      "371/371 - 1s - loss: 0.2117 - accuracy: 0.9211 - val_loss: 0.2801 - val_accuracy: 0.9119\n",
      "HALA_csp_1d_input_Full_CNN: Fold 6 : f1_macroscore: 0.8147\n",
      "HALA_csp_1d_input_Full_CNN: Fold 6 : f1_weightedscore: 0.9072\n",
      "HALA_csp_1d_input_Full_CNN: Fold 6 : acc: 0.9166\n",
      "Model: \"sequential_1081\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3243 (Conv1D)         (None, 6, 16)             64        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3243 (Aver (None, 3, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3244 (Conv1D)         (None, 3, 32)             1568      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3244 (Aver (None, 2, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3245 (Conv1D)         (None, 2, 32)             3104      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3245 (Aver (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1081 (Flatten)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1081 (Ba (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_2162 (Dense)           (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dropout_1081 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2163 (Dense)           (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_1081 (Activation) (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 9,346\n",
      "Trainable params: 9,282\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "371/371 - 1s - loss: 0.2114 - accuracy: 0.9228 - val_loss: 0.2899 - val_accuracy: 0.9134\n",
      "Epoch 2/30\n",
      "371/371 - 1s - loss: 0.2111 - accuracy: 0.9245 - val_loss: 0.2572 - val_accuracy: 0.9248\n",
      "Epoch 3/30\n",
      "371/371 - 1s - loss: 0.2195 - accuracy: 0.9189 - val_loss: 0.2898 - val_accuracy: 0.9058\n",
      "Epoch 4/30\n",
      "371/371 - 1s - loss: 0.2089 - accuracy: 0.9191 - val_loss: 0.2787 - val_accuracy: 0.9081\n",
      "Epoch 5/30\n",
      "371/371 - 1s - loss: 0.2157 - accuracy: 0.9203 - val_loss: 0.3130 - val_accuracy: 0.9180\n",
      "Epoch 6/30\n",
      "371/371 - 1s - loss: 0.2172 - accuracy: 0.9235 - val_loss: 0.3149 - val_accuracy: 0.8800\n",
      "Epoch 7/30\n",
      "371/371 - 1s - loss: 0.2133 - accuracy: 0.9215 - val_loss: 0.2688 - val_accuracy: 0.9210\n",
      "Epoch 8/30\n",
      "371/371 - 1s - loss: 0.2093 - accuracy: 0.9217 - val_loss: 0.2710 - val_accuracy: 0.9081\n",
      "Epoch 9/30\n",
      "371/371 - 1s - loss: 0.2141 - accuracy: 0.9217 - val_loss: 0.3095 - val_accuracy: 0.8603\n",
      "Epoch 10/30\n",
      "371/371 - 1s - loss: 0.2187 - accuracy: 0.9217 - val_loss: 0.2337 - val_accuracy: 0.9226\n",
      "Epoch 11/30\n",
      "371/371 - 1s - loss: 0.2171 - accuracy: 0.9199 - val_loss: 0.3290 - val_accuracy: 0.8815\n",
      "Epoch 12/30\n",
      "371/371 - 1s - loss: 0.2149 - accuracy: 0.9217 - val_loss: 0.2501 - val_accuracy: 0.9210\n",
      "Epoch 13/30\n",
      "371/371 - 1s - loss: 0.2117 - accuracy: 0.9197 - val_loss: 0.4566 - val_accuracy: 0.8967\n",
      "Epoch 14/30\n",
      "371/371 - 1s - loss: 0.2155 - accuracy: 0.9228 - val_loss: 0.3406 - val_accuracy: 0.8755\n",
      "Epoch 15/30\n",
      "371/371 - 1s - loss: 0.2037 - accuracy: 0.9228 - val_loss: 0.3431 - val_accuracy: 0.8793\n",
      "Epoch 16/30\n",
      "371/371 - 1s - loss: 0.2170 - accuracy: 0.9207 - val_loss: 0.2813 - val_accuracy: 0.8975\n",
      "Epoch 17/30\n",
      "371/371 - 1s - loss: 0.2062 - accuracy: 0.9244 - val_loss: 0.3500 - val_accuracy: 0.9104\n",
      "Epoch 18/30\n",
      "371/371 - 1s - loss: 0.2096 - accuracy: 0.9247 - val_loss: 0.2486 - val_accuracy: 0.9172\n",
      "Epoch 19/30\n",
      "371/371 - 1s - loss: 0.2090 - accuracy: 0.9246 - val_loss: 0.2582 - val_accuracy: 0.9233\n",
      "Epoch 20/30\n",
      "371/371 - 1s - loss: 0.1997 - accuracy: 0.9230 - val_loss: 0.3451 - val_accuracy: 0.9210\n",
      "Epoch 21/30\n",
      "371/371 - 1s - loss: 0.2043 - accuracy: 0.9256 - val_loss: 0.2757 - val_accuracy: 0.9043\n",
      "Epoch 22/30\n",
      "371/371 - 1s - loss: 0.1950 - accuracy: 0.9252 - val_loss: 0.2890 - val_accuracy: 0.9203\n",
      "Epoch 23/30\n",
      "371/371 - 1s - loss: 0.1947 - accuracy: 0.9249 - val_loss: 0.2650 - val_accuracy: 0.9233\n",
      "Epoch 24/30\n",
      "371/371 - 1s - loss: 0.2038 - accuracy: 0.9253 - val_loss: 0.2830 - val_accuracy: 0.9134\n",
      "Epoch 25/30\n",
      "371/371 - 1s - loss: 0.2033 - accuracy: 0.9254 - val_loss: 0.2686 - val_accuracy: 0.9248\n",
      "Epoch 26/30\n",
      "371/371 - 1s - loss: 0.1995 - accuracy: 0.9211 - val_loss: 0.4066 - val_accuracy: 0.8770\n",
      "Epoch 27/30\n",
      "371/371 - 1s - loss: 0.2011 - accuracy: 0.9263 - val_loss: 0.2716 - val_accuracy: 0.9286\n",
      "Epoch 28/30\n",
      "371/371 - 1s - loss: 0.2129 - accuracy: 0.9223 - val_loss: 0.2583 - val_accuracy: 0.9127\n",
      "Epoch 29/30\n",
      "371/371 - 1s - loss: 0.2021 - accuracy: 0.9277 - val_loss: 0.2699 - val_accuracy: 0.9241\n",
      "Epoch 30/30\n",
      "371/371 - 1s - loss: 0.2094 - accuracy: 0.9247 - val_loss: 0.2991 - val_accuracy: 0.8808\n",
      "HALA_csp_1d_input_Full_CNN: Fold 7 : f1_macroscore: 0.8297\n",
      "HALA_csp_1d_input_Full_CNN: Fold 7 : f1_weightedscore: 0.8979\n",
      "HALA_csp_1d_input_Full_CNN: Fold 7 : acc: 0.8900\n",
      "Model: \"sequential_1081\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3243 (Conv1D)         (None, 6, 16)             64        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3243 (Aver (None, 3, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3244 (Conv1D)         (None, 3, 32)             1568      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3244 (Aver (None, 2, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3245 (Conv1D)         (None, 2, 32)             3104      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3245 (Aver (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1081 (Flatten)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1081 (Ba (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_2162 (Dense)           (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dropout_1081 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2163 (Dense)           (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_1081 (Activation) (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 9,346\n",
      "Trainable params: 9,282\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371/371 - 1s - loss: 0.2088 - accuracy: 0.9226 - val_loss: 0.4007 - val_accuracy: 0.9180\n",
      "Epoch 2/30\n",
      "371/371 - 1s - loss: 0.2009 - accuracy: 0.9248 - val_loss: 0.2871 - val_accuracy: 0.9271\n",
      "Epoch 3/30\n",
      "371/371 - 1s - loss: 0.2094 - accuracy: 0.9242 - val_loss: 0.2871 - val_accuracy: 0.9203\n",
      "Epoch 4/30\n",
      "371/371 - 1s - loss: 0.2041 - accuracy: 0.9266 - val_loss: 0.5409 - val_accuracy: 0.8907\n",
      "Epoch 5/30\n",
      "371/371 - 1s - loss: 0.1982 - accuracy: 0.9272 - val_loss: 0.3293 - val_accuracy: 0.9180\n",
      "Epoch 6/30\n",
      "371/371 - 1s - loss: 0.1989 - accuracy: 0.9257 - val_loss: 0.2924 - val_accuracy: 0.9226\n",
      "Epoch 7/30\n",
      "371/371 - 1s - loss: 0.1982 - accuracy: 0.9242 - val_loss: 0.2583 - val_accuracy: 0.9233\n",
      "Epoch 8/30\n",
      "371/371 - 1s - loss: 0.2131 - accuracy: 0.9231 - val_loss: 0.3113 - val_accuracy: 0.9096\n",
      "Epoch 9/30\n",
      "371/371 - 1s - loss: 0.2056 - accuracy: 0.9263 - val_loss: 0.3071 - val_accuracy: 0.9157\n",
      "Epoch 10/30\n",
      "371/371 - 1s - loss: 0.2077 - accuracy: 0.9260 - val_loss: 0.2951 - val_accuracy: 0.9188\n",
      "Epoch 11/30\n",
      "371/371 - 1s - loss: 0.2120 - accuracy: 0.9230 - val_loss: 0.3651 - val_accuracy: 0.8793\n",
      "Epoch 12/30\n",
      "371/371 - 1s - loss: 0.2031 - accuracy: 0.9230 - val_loss: 0.2666 - val_accuracy: 0.9134\n",
      "Epoch 13/30\n",
      "371/371 - 1s - loss: 0.1909 - accuracy: 0.9277 - val_loss: 0.2702 - val_accuracy: 0.8975\n",
      "Epoch 14/30\n",
      "371/371 - 1s - loss: 0.1989 - accuracy: 0.9248 - val_loss: 0.2741 - val_accuracy: 0.9127\n",
      "Epoch 15/30\n",
      "371/371 - 1s - loss: 0.2024 - accuracy: 0.9270 - val_loss: 0.2587 - val_accuracy: 0.9142\n",
      "Epoch 16/30\n",
      "371/371 - 1s - loss: 0.2063 - accuracy: 0.9257 - val_loss: 0.2413 - val_accuracy: 0.9263\n",
      "Epoch 17/30\n",
      "371/371 - 1s - loss: 0.2023 - accuracy: 0.9259 - val_loss: 0.2862 - val_accuracy: 0.9165\n",
      "Epoch 18/30\n",
      "371/371 - 1s - loss: 0.2093 - accuracy: 0.9269 - val_loss: 0.3564 - val_accuracy: 0.9203\n",
      "Epoch 19/30\n",
      "371/371 - 1s - loss: 0.2091 - accuracy: 0.9265 - val_loss: 0.3110 - val_accuracy: 0.9172\n",
      "Epoch 20/30\n",
      "371/371 - 1s - loss: 0.2047 - accuracy: 0.9247 - val_loss: 0.3112 - val_accuracy: 0.9271\n",
      "Epoch 21/30\n",
      "371/371 - 1s - loss: 0.2058 - accuracy: 0.9259 - val_loss: 0.2885 - val_accuracy: 0.8967\n",
      "Epoch 22/30\n",
      "371/371 - 1s - loss: 0.2071 - accuracy: 0.9246 - val_loss: 0.2663 - val_accuracy: 0.9157\n",
      "Epoch 23/30\n",
      "371/371 - 1s - loss: 0.2122 - accuracy: 0.9213 - val_loss: 0.3471 - val_accuracy: 0.9241\n",
      "Epoch 24/30\n",
      "371/371 - 1s - loss: 0.2086 - accuracy: 0.9262 - val_loss: 0.3111 - val_accuracy: 0.9188\n",
      "Epoch 25/30\n",
      "371/371 - 1s - loss: 0.2054 - accuracy: 0.9274 - val_loss: 0.4990 - val_accuracy: 0.8967\n",
      "Epoch 26/30\n",
      "371/371 - 1s - loss: 0.2111 - accuracy: 0.9241 - val_loss: 0.3014 - val_accuracy: 0.9005\n",
      "Epoch 27/30\n",
      "371/371 - 1s - loss: 0.2121 - accuracy: 0.9218 - val_loss: 0.2862 - val_accuracy: 0.9127\n",
      "Epoch 28/30\n",
      "371/371 - 1s - loss: 0.2053 - accuracy: 0.9244 - val_loss: 0.2880 - val_accuracy: 0.9127\n",
      "Epoch 29/30\n",
      "371/371 - 1s - loss: 0.2046 - accuracy: 0.9269 - val_loss: 0.3235 - val_accuracy: 0.9157\n",
      "Epoch 30/30\n",
      "371/371 - 1s - loss: 0.1986 - accuracy: 0.9267 - val_loss: 0.5582 - val_accuracy: 0.8603\n",
      "HALA_csp_1d_input_Full_CNN: Fold 8 : f1_macroscore: 0.5992\n",
      "HALA_csp_1d_input_Full_CNN: Fold 8 : f1_weightedscore: 0.8180\n",
      "HALA_csp_1d_input_Full_CNN: Fold 8 : acc: 0.8626\n",
      "Model: \"sequential_1081\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3243 (Conv1D)         (None, 6, 16)             64        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3243 (Aver (None, 3, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3244 (Conv1D)         (None, 3, 32)             1568      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3244 (Aver (None, 2, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3245 (Conv1D)         (None, 2, 32)             3104      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3245 (Aver (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1081 (Flatten)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1081 (Ba (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_2162 (Dense)           (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dropout_1081 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2163 (Dense)           (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_1081 (Activation) (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 9,346\n",
      "Trainable params: 9,282\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "371/371 - 1s - loss: 0.2025 - accuracy: 0.9262 - val_loss: 0.2548 - val_accuracy: 0.9188\n",
      "Epoch 2/30\n",
      "371/371 - 1s - loss: 0.2066 - accuracy: 0.9256 - val_loss: 0.2393 - val_accuracy: 0.9104\n",
      "Epoch 3/30\n",
      "371/371 - 1s - loss: 0.2041 - accuracy: 0.9247 - val_loss: 0.2492 - val_accuracy: 0.9203\n",
      "Epoch 4/30\n",
      "371/371 - 1s - loss: 0.1941 - accuracy: 0.9267 - val_loss: 0.2907 - val_accuracy: 0.9233\n",
      "Epoch 5/30\n",
      "371/371 - 1s - loss: 0.2029 - accuracy: 0.9241 - val_loss: 0.3130 - val_accuracy: 0.9104\n",
      "Epoch 6/30\n",
      "371/371 - 1s - loss: 0.2064 - accuracy: 0.9236 - val_loss: 0.2722 - val_accuracy: 0.9021\n",
      "Epoch 7/30\n",
      "371/371 - 1s - loss: 0.2012 - accuracy: 0.9254 - val_loss: 0.2478 - val_accuracy: 0.9203\n",
      "Epoch 8/30\n",
      "371/371 - 1s - loss: 0.2028 - accuracy: 0.9268 - val_loss: 0.3062 - val_accuracy: 0.9150\n",
      "Epoch 9/30\n",
      "371/371 - 1s - loss: 0.1974 - accuracy: 0.9262 - val_loss: 0.3300 - val_accuracy: 0.9256\n",
      "Epoch 10/30\n",
      "371/371 - 1s - loss: 0.1976 - accuracy: 0.9255 - val_loss: 0.3012 - val_accuracy: 0.9188\n",
      "Epoch 11/30\n",
      "371/371 - 1s - loss: 0.1915 - accuracy: 0.9252 - val_loss: 0.2653 - val_accuracy: 0.9241\n",
      "Epoch 12/30\n",
      "371/371 - 1s - loss: 0.2002 - accuracy: 0.9252 - val_loss: 0.2368 - val_accuracy: 0.9210\n",
      "Epoch 13/30\n",
      "371/371 - 1s - loss: 0.1977 - accuracy: 0.9262 - val_loss: 0.2515 - val_accuracy: 0.9104\n",
      "Epoch 14/30\n",
      "371/371 - 1s - loss: 0.2030 - accuracy: 0.9257 - val_loss: 0.3617 - val_accuracy: 0.8922\n",
      "Epoch 15/30\n",
      "371/371 - 1s - loss: 0.2008 - accuracy: 0.9263 - val_loss: 0.2600 - val_accuracy: 0.9172\n",
      "Epoch 16/30\n",
      "371/371 - 1s - loss: 0.2021 - accuracy: 0.9259 - val_loss: 0.4227 - val_accuracy: 0.9172\n",
      "Epoch 17/30\n",
      "371/371 - 1s - loss: 0.1999 - accuracy: 0.9260 - val_loss: 0.3336 - val_accuracy: 0.9104\n",
      "Epoch 18/30\n",
      "371/371 - 1s - loss: 0.2057 - accuracy: 0.9236 - val_loss: 0.2941 - val_accuracy: 0.9096\n",
      "Epoch 19/30\n",
      "371/371 - 1s - loss: 0.1948 - accuracy: 0.9264 - val_loss: 0.3604 - val_accuracy: 0.9180\n",
      "Epoch 20/30\n",
      "371/371 - 1s - loss: 0.2069 - accuracy: 0.9228 - val_loss: 0.2495 - val_accuracy: 0.9058\n",
      "Epoch 21/30\n",
      "371/371 - 1s - loss: 0.2004 - accuracy: 0.9263 - val_loss: 0.3527 - val_accuracy: 0.9210\n",
      "Epoch 22/30\n",
      "371/371 - 1s - loss: 0.2080 - accuracy: 0.9247 - val_loss: 0.3010 - val_accuracy: 0.9279\n",
      "Epoch 23/30\n",
      "371/371 - 1s - loss: 0.2067 - accuracy: 0.9274 - val_loss: 0.3630 - val_accuracy: 0.9112\n",
      "Epoch 24/30\n",
      "371/371 - 1s - loss: 0.2112 - accuracy: 0.9267 - val_loss: 0.2682 - val_accuracy: 0.9188\n",
      "Epoch 25/30\n",
      "371/371 - 1s - loss: 0.2041 - accuracy: 0.9224 - val_loss: 0.3510 - val_accuracy: 0.9180\n",
      "Epoch 26/30\n",
      "371/371 - 1s - loss: 0.2038 - accuracy: 0.9239 - val_loss: 0.2298 - val_accuracy: 0.9203\n",
      "Epoch 27/30\n",
      "371/371 - 1s - loss: 0.2065 - accuracy: 0.9252 - val_loss: 0.2490 - val_accuracy: 0.9226\n",
      "Epoch 28/30\n",
      "371/371 - 1s - loss: 0.1955 - accuracy: 0.9281 - val_loss: 0.5275 - val_accuracy: 0.8998\n",
      "Epoch 29/30\n",
      "371/371 - 1s - loss: 0.2034 - accuracy: 0.9253 - val_loss: 0.2615 - val_accuracy: 0.9112\n",
      "Epoch 30/30\n",
      "371/371 - 1s - loss: 0.1970 - accuracy: 0.9263 - val_loss: 0.2255 - val_accuracy: 0.9218\n",
      "HALA_csp_1d_input_Full_CNN: Fold 9 : f1_macroscore: 0.8487\n",
      "HALA_csp_1d_input_Full_CNN: Fold 9 : f1_weightedscore: 0.9216\n",
      "HALA_csp_1d_input_Full_CNN: Fold 9 : acc: 0.9262\n",
      "Model: \"sequential_1081\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3243 (Conv1D)         (None, 6, 16)             64        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3243 (Aver (None, 3, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3244 (Conv1D)         (None, 3, 32)             1568      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3244 (Aver (None, 2, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3245 (Conv1D)         (None, 2, 32)             3104      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3245 (Aver (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1081 (Flatten)       (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1081 (Ba (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_2162 (Dense)           (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dropout_1081 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2163 (Dense)           (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_1081 (Activation) (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 9,346\n",
      "Trainable params: 9,282\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371/371 - 1s - loss: 0.2042 - accuracy: 0.9240 - val_loss: 0.2394 - val_accuracy: 0.9271\n",
      "Epoch 2/30\n",
      "371/371 - 1s - loss: 0.1957 - accuracy: 0.9274 - val_loss: 0.2899 - val_accuracy: 0.9210\n",
      "Epoch 3/30\n",
      "371/371 - 1s - loss: 0.1969 - accuracy: 0.9269 - val_loss: 0.2895 - val_accuracy: 0.9112\n",
      "Epoch 4/30\n",
      "371/371 - 1s - loss: 0.2080 - accuracy: 0.9249 - val_loss: 0.2848 - val_accuracy: 0.9218\n",
      "Epoch 5/30\n",
      "371/371 - 1s - loss: 0.2003 - accuracy: 0.9264 - val_loss: 0.3277 - val_accuracy: 0.9021\n",
      "Epoch 6/30\n",
      "371/371 - 1s - loss: 0.1988 - accuracy: 0.9233 - val_loss: 0.3475 - val_accuracy: 0.8724\n",
      "Epoch 7/30\n",
      "371/371 - 1s - loss: 0.2013 - accuracy: 0.9237 - val_loss: 0.2808 - val_accuracy: 0.9180\n",
      "Epoch 8/30\n",
      "371/371 - 1s - loss: 0.1974 - accuracy: 0.9254 - val_loss: 0.3039 - val_accuracy: 0.9248\n",
      "Epoch 9/30\n",
      "371/371 - 1s - loss: 0.2065 - accuracy: 0.9256 - val_loss: 0.2476 - val_accuracy: 0.9165\n",
      "Epoch 10/30\n",
      "371/371 - 1s - loss: 0.2031 - accuracy: 0.9284 - val_loss: 0.2341 - val_accuracy: 0.9150\n",
      "Epoch 11/30\n",
      "371/371 - 1s - loss: 0.1959 - accuracy: 0.9292 - val_loss: 0.2881 - val_accuracy: 0.9104\n",
      "Epoch 12/30\n",
      "371/371 - 1s - loss: 0.1925 - accuracy: 0.9319 - val_loss: 0.2608 - val_accuracy: 0.9172\n",
      "Epoch 13/30\n",
      "371/371 - 1s - loss: 0.1989 - accuracy: 0.9271 - val_loss: 0.2902 - val_accuracy: 0.8815\n",
      "Epoch 14/30\n",
      "371/371 - 1s - loss: 0.1998 - accuracy: 0.9264 - val_loss: 0.3455 - val_accuracy: 0.8793\n",
      "Epoch 15/30\n",
      "371/371 - 1s - loss: 0.2086 - accuracy: 0.9276 - val_loss: 0.2391 - val_accuracy: 0.9195\n",
      "Epoch 16/30\n",
      "371/371 - 1s - loss: 0.2014 - accuracy: 0.9253 - val_loss: 0.2310 - val_accuracy: 0.9203\n",
      "Epoch 17/30\n",
      "371/371 - 1s - loss: 0.1957 - accuracy: 0.9271 - val_loss: 0.2522 - val_accuracy: 0.9317\n",
      "Epoch 18/30\n",
      "371/371 - 1s - loss: 0.2003 - accuracy: 0.9275 - val_loss: 0.3489 - val_accuracy: 0.9058\n",
      "Epoch 19/30\n",
      "371/371 - 1s - loss: 0.1963 - accuracy: 0.9257 - val_loss: 0.2385 - val_accuracy: 0.9172\n",
      "Epoch 20/30\n",
      "371/371 - 1s - loss: 0.1974 - accuracy: 0.9269 - val_loss: 0.2366 - val_accuracy: 0.9256\n",
      "Epoch 21/30\n",
      "371/371 - 1s - loss: 0.2019 - accuracy: 0.9269 - val_loss: 0.2239 - val_accuracy: 0.9271\n",
      "Epoch 22/30\n",
      "371/371 - 1s - loss: 0.1980 - accuracy: 0.9259 - val_loss: 0.3238 - val_accuracy: 0.9248\n",
      "Epoch 23/30\n",
      "371/371 - 1s - loss: 0.1977 - accuracy: 0.9290 - val_loss: 0.2448 - val_accuracy: 0.9241\n",
      "Epoch 24/30\n",
      "371/371 - 1s - loss: 0.1992 - accuracy: 0.9288 - val_loss: 0.2280 - val_accuracy: 0.9271\n",
      "Epoch 25/30\n",
      "371/371 - 1s - loss: 0.1947 - accuracy: 0.9284 - val_loss: 0.2304 - val_accuracy: 0.9286\n",
      "Epoch 26/30\n",
      "371/371 - 1s - loss: 0.1967 - accuracy: 0.9272 - val_loss: 0.2545 - val_accuracy: 0.9165\n",
      "Epoch 27/30\n",
      "371/371 - 1s - loss: 0.1988 - accuracy: 0.9294 - val_loss: 0.7422 - val_accuracy: 0.8702\n",
      "Epoch 28/30\n",
      "371/371 - 1s - loss: 0.1987 - accuracy: 0.9269 - val_loss: 0.2510 - val_accuracy: 0.9150\n",
      "Epoch 29/30\n",
      "371/371 - 1s - loss: 0.1973 - accuracy: 0.9267 - val_loss: 0.2779 - val_accuracy: 0.9279\n",
      "Epoch 30/30\n",
      "371/371 - 1s - loss: 0.1890 - accuracy: 0.9299 - val_loss: 0.4148 - val_accuracy: 0.9218\n",
      "HALA_csp_1d_input_Full_CNN: Fold 10 : f1_macroscore: 0.7986\n",
      "HALA_csp_1d_input_Full_CNN: Fold 10 : f1_weightedscore: 0.8993\n",
      "HALA_csp_1d_input_Full_CNN: Fold 10 : acc: 0.9098\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWIAAAEICAYAAABlM/5GAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAm9UlEQVR4nO3deXxU5fXH8c/JRhIChE3ZBYWCuKGyaKuIFhRwQesG2roXbdVfN1u1danWaq1drQuidWmtgiJVUKxa61oEgYriAhL2sCirQEIgIef3x72JM5NtgISbjN/363VfzNz7zLnPndw588y5C+buiIhIdNKi7oCIyFedErGISMSUiEVEIqZELCISMSViEZGIKRGLiERMiTgCZuZm1rOBYp9vZi/HPP+GmS00s61mdrqZvWhmFzbAeseZ2Y0NENfM7BEz22hm79Z3fGl8zOyXZvZ4+Lh7+HnJiLpfDWmvJmIzW2pmQxPmXWRmb1fT9vXww9dsL/Sr2j5U08bN7Jwk4nU0s7+a2Woz22Jm883sFjNrXn+9rp67/8PdT4yZdStwj7vnufuz7j7C3R/bk3VU9365+xXu/qs9iVuDY4BhQBd3H1gfAc0sK/ywLzSzonC/fNjMuofLDzKzl8P9b5OZzTGzkeGyIWZWHn6xbTGzBWZ2cQ3riW1bMU3dw74PMbPCPYmxtzTE9qeqRjkiDj8QxwIOnBZtbypdCGwI/62RmbUB3gFygKPdvQVBIskHDmjgPlZnP+CjCNZbX/YDlrp70a6+sJZR1CSC/eo8oBVwGDAH+Ga4fCrwCrAvsA/wf8DmmNevcvc8oCVwLfCgmfWtYV2rwi/BiunUXd2O+hTByLJRbX+j5e57bQKWAkMT5l0EvJ0w7ybgv8AfgOdriTcamJ0w70fAlPDxSOBjYAuwErimhjhV+pCwfD+gHDgTKAP2raXtbcA8IK2WNg70DB+fDLxH8EFfAfwypl028DiwHtgEzKpYd9jnxeG2LQHOT9wWYFHY723AVqAZ8DpwWcw6vgt8Esb5GDginH9d+PqK+WeE8w8ESoCdYcxN4fxHgdsS4hYQfHlNATolbP8VwEJgI3AvYNW8T5cmrOuWJGNfGcZeUk3MoeH70bWGv027MEZ+DcuHAIUJ89YCZyXTNmbZUcD08O/6PjAkZtnFMX+TxcDl4fzmYd/Lw/djK9Cpmvc+br0En7trgQ+A7UBGHeu/iGr2rd34vFe7/TW8h0sJcwPwS+Dx8HH38O+RsTt9aCrT3l1Z8om4APg+cCRQSg2JD8gNd5ZeMfNmAaPDx6uBY8PHrQmTTDVxqvQhYfmNwLvh43nAj2tpO4MwYdTSJjYRDwEOIfh1cijwGXB6uOxygtFZLpAevh8tww/kZqB32K4jcFB125L4nhOTiIGzCb6gBgAG9AT2i1nWKezXuUAR0LGWv9mjhMkAOAFYBxxBkPz/AryZsP3PE/xK6EaQyIYn87dJMvYrQBsgp5p4vwHeqOVvYwRJ/Hng9MR9j5gkEr43ZxDso72riVXZNmF+Z4Iv15FhjGHh8/bh8pMJfj0ZcBxQzJdfkFViklwingt0JfilVuP6qWXf2o3Pe03bX902LOUrnIijKE08G9bdNpnZJuC+2IVmdgzBCPQpd59DMCo7r7pA7l4MPAeMCV/bC+hDMEqC4APS18xauvtGd//fbvb5AuCJ8PET1F6eaEvwBZAUd3/d3ee5e7m7fwA8SfDhg6D/bQmS9k53n+PuFT+Ry4GDzSzH3Ve7++6UHy4DfuvuszxQ4O7Lwn497e6rwn5NJEhOydZozwcedvf/uft24Hrg6IoabOg37r7J3ZcDrwH96jH2He6+wd23VfP6Wv8+Hnz6jydIDL8HVpvZm+G+VaFTuO+uA24GvuPuC2oI2Sl2fw+PMXwbmObu08L39xVgNkFixN1fcPdF4d/kDeBlglLdnrjb3VeE70mt66d+9q0K1W2/JIgiEZ/u7vkVE8HIN9aFwMvuvi58Xlfie4IwERMk7GfDBA1BKWEksMzM3jCzo3e1s2b2DaAHMCFmfYeYWb8aXrKeYBSRbPxBZvaama01sy8IfrK3Cxf/HXgJmGBmq8zst2aW6UG99Nyw7Woze8HM+uzqthGMkBbV0K8LzGxuzBfmwTH9qksnYFnFE3ffSvC+dI5psybmcTGQV4+xV9Ty+jr/Pu5e6O5XufsBBIOCIuBvMU1WhftvG3fv5+4Tqo8U17ZieiqMeXbCgOSYin6Z2Qgzm2FmG8JlI0n+va9J7HtS4/p3Zd9KOAjXbRe2XxI0qoN1ZpYDnAMcZ2ZrzGwNQc33MDM7rIaXvQy0CxPjGL4cuRKO9EYRHHB5FtidneBCgp+Ic8P+zAznX1BD+38DZ5hZsu/tEwQj+K7u3goYF64Pdy9191vcvS/wdeCUivW6+0vuPozgwzsfeHCXtyz4cFY5gGhm+4XxrgLahl+YH1b0i+CnYm1WEXzYK+I1JxiJrtyNPu5O7Nr6929goJl1SWZl7r6CoIZ98K53tUYrgL8nJKjm7v6b8CyhZ4DfEZRF8oFp1P7eFxGUryp0qKZN7OtqXD8kv295/EG45UlvfUJ/zSydoCzyldWoEjFBTW4n0Jfgp2o/goNDb1FD4nP3MoKj4HcR1AVfgcpTlM43s1buXkpQ99pZy7rNzLITJ4IvhrEx/ekHXA2cX8MR6D8Q1HEfCxMaZtbZzP5gZodW074FsMHdS8xsIDFlGDM73swOCXfUzQSlip1mtq+ZnRYmoe0EB21q27aaPARcY2ZHWqBn2OfmBB/ctWE/LiY+EX0GdDGzrBriPgFcbGb9wsRyOzDT3ZfuRh/rNba7/5tgH/lnuN0ZZtbCzK4ws0vMrLUFpxr2NLM0M2sHXEJQ+68vjwOnmtlJZpYe7mtDwi+HLILa91qgzMxGALGnI34GtDWzVjHz5gIjzayNmXUAfri766/Hfas2nwLZZnaymWUCNxBs81dWY0vEFwKPuPtyd19TMQH3UHPig+DDORR4OkzMFb4DLDWzzQQ/tb5dy7q/TnBEOnY6K/z3bwn9+SvBwbPhiUHcfUMYqxSYaWZbgFeBLwgOQib6PnBr2O4m4kftHQi+ZDYTHEV/g+BDlAb8hGB0uIGgppxY4qmTuz8N/Jrg/dtC8Kuhjbt/TFAffYfgg38IwVksFf5DcErcGjNbRwJ3f5XgAOczBPXYAwjOcNlj9RT7LIJR5kSCv8uHQH+C0fIOggNE/yZ43z8kSEgX7XHnQ+EoexTwc4KEuwL4KcGZNlsITpd7iuCMkvP48pgH7j6f4DjC4rCs0ImghPU+QV375XC7dmv91NO+Vcf6vwhjPkTwS6YIaBLnRjcUC45NiIhIVBrbiFhE5CtHiVhEJEkWXAr/uZl9WMNyM7O7zazAzD4wsyOSiatELCKSvEep5thQjBFAr3AaC9yfTFAlYhGRJLn7mwQHMWsyiuDgvrv7DCDfzOq8riCSW8t1+/MbOkIocS4dXBp1F6QRuvnwoVZ3q9rldBuTdL4pWTHhcoKRbIXx7j5+F1bXmfiLZwrDebVebZvS9/gUEdkVYdLdlcSbqLovjjq/CJSIRSSlJX+Ra70oJLh1QIUuBOdk10o1YhFJaWmWkfRUD6YAF4RnTxwFfOHudd4ETCNiEUlp9TkiNrMnCW7j2c6C/ynlZiATwN3HEVyxOZLgKtpigntL10mJWERSmtkeH++r5O5j6lhe8R8T7BIlYhFJcY2/AqtELCIpbS8frNstSsQiktKUiEVEIlZPZ0M0qMbfQxGRPaARsYhIxJSIRUQiZtVeddy4KBGLSErTiFhEJGJpaY0/zTX+HoqI7BGNiEVEIqXShIhIxJSIRUQiZipNiIhESyNiEZGIpaWlR92FOikRi0hKU2lCRCRiKk2IiERMiVhEJGIqTYiIRMx0ibOISLTq8z8PbShKxCKS0lSaEBGJmA7WiYhETaUJEZGINf4BsRKxiKS4tMafiZWIRSS1Nf48rEQsIqnNVSMWEYlY48/DSsQikuLSGn8mViIWkdSm0oSISMTSlYhFRKKlEbGISMQafx5WIhaRFNcEDtY1gVOdRUT2gO3ClEw4s+FmtsDMCszsumqWtzKzqWb2vpl9ZGYX1xVTI2IRSWmeXn/jTTNLB+4FhgGFwCwzm+LuH8c0uxL42N1PNbP2wAIz+4e776gprkbEIpLa6ndEPBAocPfFYWKdAIxKaONACwvuSJ8HbADKaguqRCwiqc0s6cnMxprZ7JhpbEK0zsCKmOeF4bxY9wAHAquAecAP3L28ti6qNCEiqW0XDta5+3hgfC1NqgvmCc9PAuYCJwAHAK+Y2VvuvrnGLibdQxGRpqh+SxOFQNeY510IRr6xLgYme6AAWAL0qS2oErGIpLZdKE0kYRbQy8x6mFkWMBqYktBmOfDNYNW2L9AbWFxbUJUmRCS11eMlzu5eZmZXAS8B6cDD7v6RmV0RLh8H/Ap41MzmEYyzr3X3dbXFVSIWkdRWz5c4u/s0YFrCvHExj1cBJ+5KTCXiXdSqWQZ3De3N4P1as2FbKXdOX8JzCz6vtm23ltncMqQngzq3YsdO56mP1nD7fxeTlW7cdnwvjunamvzsDJZu2sZvpy/l9WUbAOjSohnTLzmKoh07K2PdP2c5d7+7PC5+Zprx0vn9aZ6ZzqCHZzTcRkudtm8tYuYD/2D1B5/QrEVz+o0eRfdjBlRpt3T6bOY9/QIlmzaTlplBp34H0f+is8nMzQHgqQt/FNd+545Sep04mP4XnxM3f96kF5g3aRon/OJqOhzyZflxw5LlzHlsEhuXrCAjuxl9R51En5HHN8AWNyGN/8I6JeJdddvxvSgtL+eIB6dzUPs8HjntED5Zu5VPNxTHtctMM/5xxqE89sEqvj/tY8rd6dE6F4B0M1Zv2c45k+aycst2TujRhvtGHsiJj8+mcMv2yhgHj3ubnYnHY2NcfmRX1m/bQfPMnAbZVkne7IcnkpaezrceuIONSwt54877yd+vM/ldO8W1a/+1Axh2y0/IbplHaUkJ7z74JO8/NZX+FwWJ9pzH/ljZtqxkO5Mvv45uRx0eF2PLmrUsnzmXnNat4uaXbN7Ka3fcyxEXnEm3QYdTXraT4g2bGmaDmxBPpUuczWxrLcv+bGYrzSylD/7lZKQxomc7fvfOUopLy5m1ajP/Xryebx24b5W2Z/ftwGdFO3jovUK2lZWzfaczf10RANvKyvnjzGUUbtmOA68u2cCKzSUcsm+LpPvStWU2Z/TZh3tnrai7sTSospLtrJg5l0PPOYXM7Gz26dOTzkcewtK33q3Stnm71mS3zKt8bmlpbFmzttq4y2e+R7NWLWjfp2fc/NmPPEW/80aRlp4eN3/+C6/S8dAD6XHMQNIzM8nMyaZV5w71sIVNXP0erGsQezwiDpPvGQQnOQ8GXt/TmI3V/q1zKXdnyaZtlfM+XreVozrnV2l7eIcWFG4u4bFRh3DYvi1YsL6Im14vYMH6oipt2+Vm0iM/l08Tlr1zyVG4w1srNvLrtxaxseTLi3NuHdKT305fQknZzsRwspdtXv05lpZGy05ffiG33q8Ln32ysNr2n88v4I0776d0WwnpzbIY/OPEawYCS96cSY9jB2ExCWL5jP+RlpFO58MPZjYT49qvL1hKq66dePnG37Hls7W07dmdAZecS/N2bephK5uwxj8grpfT144HPgTuB8bUQ7xGq3lmOpu3xye+LdvLaJ6VXqVtx7xmnPq19jwydyUDHnqH/yxZz19PPYjMhJ9JGWnG3ScdyDOfrGHRxiDBbygp5ZQn53D0wzM4ecIc8jLTuXv4gZWvOemAtqSb8dKi9Q2wlbKrykq2k5mbHTcvMzeHsm3bq22/T5+enP3I7zn9vl9z4ClDad6+aqIsWreBzz9eyP7HDaqcV1pSwtwJUzjywrOqjVu8fhNL3pzJkRedzen33EbePm35792P7MGWpYj0tOSniNTHmscATwL/BE4xs8zqGsVeOrh1+tR6WO3eV1S6kxYJSTcvKyPuoFqFkrKgdPH6sg2UljsP/K+Q/OxMerbJrWxjwJ9O7MOO8nJufL2gcn5xaTkffL6VnQ7riku58fWFHLdfG/Ky0snJSOPnx+zPTW8UVFmnRCMjuxml20ri5pVu20ZGTrNaX5fbJp9O/fpWmyyXvDmT9n0OIG+fdpXz5j39Aj2OHRg3L1Z6ViZdBxxG2wP2Iz0rk0POHMm6Txezo3hbte2/Mur57msNYY9KE+EJzSOBH7n7FjObSXDaxguJbWMvHez25zdqOQTVeC3eWEx6mtE9P4elYXmib/vmfLqharnhk3VF9O/UstZ4dw3rTbvcLC58bh5l5TW/JRVLDOiRn0OXFtlMOqsfAFnpRousDGZfdjSnT/xf3ME+2TtadtwH31nO5tWf07LjPgBsXLaS/C4d63xt+c6dbP2sao14yZvv0nfUsLh5az5cwLYNm1j48psAbN+8lbf/9Ff6njaMvqNOJL9bp/hkUlHS8Cb5cas/qXSwrgbDgVbAPDNbChxDCpcntpWV86+CdfzkqO7kZKTRv2NLhu3fjsmffFal7T/nf8YRHVpyTNd80gwuPbwzG7eVUhCeXXH7Cb3o2TqXS6bOY/vO+PuB9Nu3Bfvn52BAfnYGtxzXk+krNrFlx04WrC/iqIdnMOKJ2Yx4YjY/+/enrCvewYgnZrNqq5JwFDKym9FlYD/mPf08ZSXbWbtgEStnf0D3YwdWabvk7XcpWrcBd6do7Xo+mDiVfQ/uHddm7YLFFG/cRLejjoib/80b/o+Rd/2CEXdez4g7ryendSsGfncMvU4aDMD+Q45mxaz32bh0BeVlO/nwmRdp3/sAsprn8pWWZslPEdnTg3VjgMvc/UkAM2sOLDGzXHcvrv2lTdMvXlvI74b15r2xX2djSSm/eG0hn24oplOLZrz67QF88/FZrNqyncWbtvGDl+Zz+wlfo21OJh+u3cqlUz+ktNzp3KIZ3z6kEyVl5cy57OuVsa//z6c8u+BzurXK5mdf70G73Cy27ijjreUbufpfwe1OdzqsLS6tfM2mklLKE+bJ3jfg0nOZOe5xnrn8OprlNWfApaPJ79qJonUbeOEnv+Lk399I83Zt2Fy4hrlPPMeOomKymufSqd9B9BtzWlysJW/OoOuAw8jMia87N2uRF/fc0tLIap5LZnbQrsPBvel37mm8fuf9lO3YQfveB/D1q+u8J3nK88Y/IMY8yZ8tZlZO/M0t7gOuAbrH3lXIzCYDE919IjVoqqUJaTiXDtYXiVR18+FD9ziN7n/5M0nnm8UPnBlJ2k56ROzu1ZUxbq+m3bf2qEciIvWpCdSIdWWdiKS2JnCZmRKxiKS2CK+YS5YSsYikNpUmRESi5RoRi4hELEOJWEQkWhoRi4hETDViEZGINf48rEQsIqmtKfwPHUrEIpLalIhFRCKWrkQsIhItnTUhIhIxlSZERCKmRCwiEi1d4iwiEjUdrBMRiZhKEyIiEVMiFhGJWOPPw0rEIpLadImziEjUdNaEiEjEdNaEiEi00prA/+LcBLooIrL7zJKfkotnw81sgZkVmNl1NbQZYmZzzewjM3ujrpgaEYtISqvPErGZpQP3AsOAQmCWmU1x949j2uQD9wHD3X25me1TV1yNiEUkpZlZ0lMSBgIF7r7Y3XcAE4BRCW3OAya7+3IAd/+8rqBKxCKS0tLSkp/MbKyZzY6ZxiaE6wysiHleGM6L9TWgtZm9bmZzzOyCuvqo0oSIpDTbheGmu48HxtcWrrqXJTzPAI4EvgnkAO+Y2Qx3/7SmoErEIpLS6vk04kKga8zzLsCqatqsc/cioMjM3gQOA2pMxCpNiEhKS7PkpyTMAnqZWQ8zywJGA1MS2jwHHGtmGWaWCwwCPqktqEbEIpLS6nNE7O5lZnYV8BKQDjzs7h+Z2RXh8nHu/omZ/Qv4ACgHHnL3D2uLq0QsIimtvq9wdvdpwLSEeeMSnt8F3JVsTCViEUlpabrEWUQkWk3gnj9KxCKS2pSIRUQipkQsIhKxJnBfeCViEUltGhGLiERMZ02IiERMI2IRkYgpEYuIREyJWEQkYjprQkQkYmnpUfegbkrEIpLSVJoQEYlYkv8XXaSUiEUkpTWBPKxELCKpTYm4BgVX50WxWmnEOvR+JOouSCN088KhexxDiVhEJGIZTeB/5lQiFpGUlmaJ/9t946NELCIpTRd0iIhErAlUJpSIRSS1qTQhIhIxlSZERCKWoUQsIhItU2lCRCRaKk2IiERMZ02IiERMZ02IiERMB+tERCKmGrGISMRUmhARiZhGxCIiEdNZEyIiEVNpQkQkYk3hxvBNoIsiIrsvbRemZJjZcDNbYGYFZnZdLe0GmNlOMzurrpgaEYtISqvP0oSZpQP3AsOAQmCWmU1x94+raXcn8FJSfay3HoqINEJplvyUhIFAgbsvdvcdwARgVDXtrgaeAT5Pqo9JbouISJO0K6UJMxtrZrNjprEJ4ToDK2KeF4bzKplZZ+AMYFyyfVRpQkRS2q6cR+zu44HxtTSpLlpi7eNPwLXuvtMsuZUrEYtISktPq9fT1wqBrjHPuwCrEtr0ByaESbgdMNLMytz92ZqCKhGLSEqr5/rrLKCXmfUAVgKjgfNiG7h7j4rHZvYo8HxtSRiUiEUkxdXnWRPuXmZmVxGcDZEOPOzuH5nZFeHypOvCsZSIRSSl1fe9Jtx9GjAtYV61CdjdL0omphKxiKQ03fRHRCRimbrXhIhItDQiFhGJmBKxiEjE0pWIRUSipRGxiEjEdGN4EZGIZWpELCISLZUmREQiptKEiEjEdNaEiEjEVJoQEYlYU/hfnJWIRSSlpatGLCISrSYwIFYiFpHUphqxiEjElIhFRCKmGrGISMR01oSISMRUmhARiZiurBMRiZjuNZGCvti0lZtuGM870+eRn9+CH/z4XE4+5RvVtv3bo9N4+K9T2V6yg6EnDuTGmy8hKyszrs2ypav51qjrGHbSQH7z2ysBeH/uQu65+2k+/ngJ6Wlp9B94INf//ELa79M67rWlO8r41unXUly8nVdfv6dhNliSkt8ql7tvP5/jj+nDho1F3Pr7KTwzdXaVdllZGdx8zWmcPvJIcrIzeeb52Vx/2yTKysoBmPL4D+jfr3vl89WfbWLQSb8C4KzT+vOHW8dUxkpLM3Jzsjj+9Dt5/6MVABzatwu333AWh/btSvG27fxx3Ms88NjrDbz1jVsTKBHXnYjNbKu758U8vwjo7+5Xxcx7H/jY3cdUEyKl/PpXj5CZmcHrb93P/PlLufKKu+jdez969uoS1+6/b7/PXx+awl8fuYH2++Tzw6v/yL1/mcSPfjImId6jHHzI/nHzNm8u4qxzTuAbxxxKeno6t9/2KDf+4gHGPXhdXLtHHn6eNm1aUVz8ecNsrCTtrl+eQ2lpGX2Ovp6DD+zCxAe/x0efFDK/YE1cux+OHUa/g7vxjZN/TXp6Gk8+cDnXfH84v7l7WmWba295ir8//U6VdUyaMptJU75M7mO+NYhrrhxemYTbtG7O0w9fyS9uf4Yp/5pLVmY6nTrkN8wGNyFNoUa8x18WZnZgGGewmTXf8y41XsXFJbzyyrtc9X9nk9s8myOO7MOQ449k6pS3qrR97tm3+NaZQ+jZqwutWuVx+ffO4Lln34xr8+IL02nRMpdBRx0UN//Ywf04afhR5OXlkpPTjDHnnch7//s0rk1h4ec8P/VtLht7Wv1vqOyS3JwsTj2xH7f/6QWKincwc85iXnx1HuecPrBK25NOOITxf3uDTV8Us37DVh742xucf9bRu7Xe0WcMYuI/3618/v2LT+A/b33CpCmz2bGjjK1F2/l00We7vV2pIjPNk56iUh+j9vOAvwMvAymdFZYtXUN6Whrde3SsnNe7TzcWFRRWabuooJDevfeLa7d+3Rds2rgFgK1bi7n3L5P46c++Xed658yeT8+e8SPuO257jB/88Fyys7N2d3OknhzQYx92lpezaOmXv0w+mr+SPr06VmlrFkyxzzt3bE2LvOzKeTdecxoLZ/6GFyf8iG8M7FXtOrt0as3XB/RkwrNfJuL+/bqz6Ysi/jXxxyyYcQdPPHA5nTu2rvb1XyVplvwUWR+TaJNjZnMrJuDWhOXnAhOBJ4EaSxNmNtbMZpvZ7IfGT97tDkepuLiEvBa5cfPy8nIpKiqps21eXvC4qDhoe8/dT3PGmUPo0LFtretcsGA54+6fzI9/el7lvFdfmcXOnTv55rABu70tUn+a5zZj85b4fWDzlm3kNc+u0vbfb37M5RcOoW2bPPZp14LLLxgCBKNqgFvuepYjTvglBx17A49NnM4TD1xO927tqsQZfcYg3pm9iOWF6yvnderQmtFnDOL62yZx6OAbWVa4nof+eFG9bWdT1RQScTIH67a5e7+KJxU14vDxAGCtuy8zs0LgYTNr7e4bE4O4+3hgPMCO8jmN/zBmNXJzsynaui1uXlHRNppX84HLzc1ma0zbitc1z81m/idLmTH9Q56efEet61u+bA3fH3sn111/AUf27wMECf4Pv3uC+x742Z5ujtSTouLtcSNagBZ52Wyt5gv6D/e9RKsWObzx3HXsKC3jbxOnc8iBXVi7PvilNOf9ZZVtJ/xzJmeeciTDjjuIB//+Rlycc08fyB/HvRw3r6RkBy+88gHvzVsOwG//8iKLZt1Ji7xstmyt2pevipQ4WFeHMUAfM1saPm8JnAk8tIdxG6X9unegbOdOli1dzX7dg5+dC+Yv44CEsgHAAT278OmCZQwfcVTQbsFy2rZrRX7rFkyd8jarVq1j2DevBoLkWr6znHMKVvLU5NsBWLVyLd+95HYu/94ZnDrq2Mq4y5etYdWqdVz4neCHSWlpGVu3FDPk2O/xjwm30rlz+wZ9D6SqRUs+JyM9jf33a8/iZWsBOKhPZ+YvXF2lbcn2Uq699WmuvfVpAC489xu8/9EKysurH5u4e1wpA2DQEfvTYZ9WTPnXe3HzP1qwCnePey2AJQb4imkKm7/bXxZmlgacDRzq7t3dvTswilrKE01dbm42Q4cO4N6/TKK4uIT3/reA1/4zh1NPO7ZK29NGHcvkZ15nUUEhX3yxlfHj/smo0wcDcNY5JzDtpT8yafIdTJp8B+ecO5TBxx3OuIeCsyI++2wDl178a0afN4xzRg+Ni9uzV1de+c9fKl97y63fpW3bVkyafAcdOtRe5pCGUbxtB8+//D7X//BkcnOyGHTE/owceihPxdRvK3TctxUd9mkFBDXda64czm/ufgGAli1yOOGYA2mWlUF6ehpnndafowf05D9vfRIXY/QZg5j60ly2Fm2Pm//EMzM4edhhHHxgZzIy0vjplcN5Z1YBm7fE/4r7qkmV0kRNBgMr3X1lzLw3gb5m1tHdqw4HUsANN13CjTc8wJBjvker/DxuuPkSevbqwupV6xh16k95bupddOzUjmOOPYyLLz2FSy66je0lpQw9cQBXXn0WADk5zcjJaVYZMze3GVnNMmnTpiUAkye9RuGKz7n/vsncf9+X9fR35zxCRkY67drnV85rlZ+HpaXFzZO975pfTuQvd5zPghl3sHFTET+5eSLzC9bQuWNr3nnxBo4ecRsrV2+ke7d23P/bC2jXtgUrV2/klt89x2tvzwcgMzOdn//oFHrtvy/l5eUsXPwZ3/n+gxQs+fIgYLOsDE4feTgXXlX1R+dbMz7lV3+YwoTx3yM3J4sZcxYx9seP7q23oNFqCqUJi/0ps7c01RqxNJwOvR+JugvSCG1YeM8ej1PfW/980vnm8LanRDIu1pV1IpLSmkCJWIlYRFJbSh+sExFpCmwXpqTimQ03swVmVmBm11Wz/Hwz+yCcppvZYXXF1IhYRFJafd4G08zSgXuBYUAhMMvMprj7xzHNlgDHuftGMxtBcP3EoNriKhGLSEqr59LEQKDA3RcHsW0CwWm7lYnY3afHtJ8BVL3QIIFKEyKS0nalNBF7K4ZwGpsQrjOwIuZ5YTivJpcCL9bVR42IRSSl7cqAOPZWDLsQrtrT48zseIJEfExd61UiFpGUVs9XzBUCXWOedwFWJTYys0MJbvUwwt3XJy5PpNKEiKS0ej5rYhbQy8x6mFkWMBqYErc+s27AZOA77v5pNTGq0IhYRFJaff6fde5eZmZXAS8B6cDD7v6RmV0RLh8H3AS0Be4Lb7hU5u79a4urRCwiKa2+L+hw92nAtIR542IeXwZctisxlYhFJKU1hfqrErGIpLSmcImzErGIpLQmkIeViEUktUV5w/dkKRGLSEpTIhYRiVgTyMNKxCKS2qwezyNuKErEIpLSNCIWEYmYTl8TEYlYetQdSIISsYikNI2IRUQi1/gzsRKxiKQ0UyIWEYmWWeO/7Y8SsYikOI2IRUQiZU3gRphKxCKS0lSaEBGJnEoTIiKR0lkTIiIRUyIWEYmYWeO/yFmJWERSnEbEIiKRUmlCRCRyOn1NRCRSGhGLiETMmsB9MJWIRSSlWRO4NbwSsYikOI2IRUQipdKEiEjklIhFRCKl22CKiEROI2IRkUil6X7EIiJRUyIWEYlUU7iyrvF/VYiI7BHbhSmJaGbDzWyBmRWY2XXVLDczuztc/oGZHVFXTCViEUlpZpb0lESsdOBeYATQFxhjZn0Tmo0AeoXTWOD+uuIqEYtISjPSk56SMBAocPfF7r4DmACMSmgzCvibB2YA+WbWsbagkdSIs9KObPxFm73EzMa6+/io+xG1DQuPjLoLjYb2ifr2taTzjZmNJRjFVhif8LfoDKyIeV4IDEoIU12bzsDqmtarEXH0xtbdRL5itE9ExN3Hu3v/mCnxC7G6pO670SaOErGISPIKga4xz7sAq3ajTRwlYhGR5M0CeplZDzPLAkYDUxLaTAEuCM+eOAr4wt1rLEuAziNuDFQLlETaJxopdy8zs6uAl4B04GF3/8jMrgiXjwOmASOBAqAYuLiuuOZea+lCREQamEoTIiIRUyIWEYmYEvFeYmZba1n2ZzNbadYEbhMl9SZxnzCzi8zsnoR575vZk3u3Z7K36YMfsTD5nkFwAvjgiLsjjYiZHUjwGR1sZs2j7o80HCXi6B0PfEhwPfqYiPsijct5wN+Bl4HTIu6LNCCdvha9McCTwHPA7WaW6e6lEfdJ9o4cM5sb87wN8eekngsMA3oDVxHsJ5KCNCKOUHhC+EjgWXffDMwEToy2V7IXbXP3fhUTcFPFAjMbAKx192XAq8ARZtY6on5KA9OIOFrDgVbAvPAWfLkEJ4C/EGWnpFEYA/Qxs6Xh85bAmcBDkfVIGoxGxNEaA1zm7t3dvTvQAzjRzHKj7ZZEKTyAezZwaMy+MQodQ0hZSsR7T66ZFcZMPwdOImb06+5FwNvAqVF1UhqFwcBKd18ZM+9NoG9d97WVpkmXOIuIREwjYhGRiCkRi4hETIlYRCRiSsQiIhFTIhYRiZgSsYhIxJSIRUQi9v8WASEUOkhaBQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and std of F1 MACRO is 0.7978 +- 0.0798\n",
      "Mean and std of F1 WEIGHTED is 0.8956 +- 0.0317\n",
      "Mean and std of accuracy is 0.9033 +- 0.0193\n"
     ]
    }
   ],
   "source": [
    "conf_mat = np.zeros((2,2))\n",
    "f = 0\n",
    "f1_MacroNet = np.zeros([foldNum,]) \n",
    "f1_weightedNet = np.zeros([foldNum,])\n",
    "precisionNet = np.zeros([foldNum,])\n",
    "recallNet = np.zeros([foldNum,])\n",
    "accNet = np.zeros([foldNum,])\n",
    "\n",
    "#channels = features.shape[2] # number of channels 14\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=100, shuffle=True)\n",
    "\n",
    "features = np.reshape(features, (features.shape[0],6,-1)) #reshaped to (None, 3, 14) for spectral\n",
    "\n",
    "for train, test in kfold.split(features, labels):\n",
    "  trainingFeatures = features[train,:,:]\n",
    "  testFeatures = features[test,:,:]\n",
    "  train_shape = trainingFeatures.shape\n",
    "  test_shape = testFeatures.shape\n",
    "  \n",
    "  # Standerdize \n",
    "  scaler = StandardScaler()\n",
    "  trainingFeatures = np.reshape(trainingFeatures, [train_shape[0], train_shape[1]*train_shape[2]])\n",
    "  testFeatures = np.reshape(testFeatures, [test_shape[0], test_shape[1]*test_shape[2]])\n",
    "  scaler.fit(trainingFeatures)\n",
    "  trainingFeatures = scaler.transform(trainingFeatures)\n",
    "  trainingFeatures = np.reshape(trainingFeatures, [train_shape[0],train_shape[1],train_shape[2]])\n",
    "  testFeatures = scaler.transform(testFeatures)\n",
    "  testFeatures = np.reshape(testFeatures,[test_shape[0], test_shape[1], test_shape[2]])\n",
    "  estimator.summary()\n",
    "  estimator.fit(trainingFeatures, labels_categorical[train,:], batch_size=32, \n",
    "                epochs=epochs, verbose=2, validation_split=0.1)\n",
    "\n",
    "  predicted_labelsNet = estimator.predict_classes(testFeatures, verbose=0)\n",
    "  predicted_probsNet = estimator.predict_proba(testFeatures,batch_size=1,verbose=0)\n",
    "  cm = confusion_matrix(labels[test,], predicted_labelsNet, labels=[0,1])\n",
    "  conf_mat = conf_mat+cm\n",
    "\n",
    "  precisionNet[f] = precision_score(labels[test,], predicted_labelsNet, average='macro')\n",
    "  recallNet[f] = recall_score(labels[test,], predicted_labelsNet, average='macro')\n",
    "  f1_MacroNet[f] = f1_score(labels[test,], predicted_labelsNet, average='macro')\n",
    "  f1_weightedNet[f] = f1_score(labels[test,], predicted_labelsNet, average='weighted')\n",
    "  accNet[f] = accuracy_score(labels[test,], predicted_labelsNet)\n",
    "  print(experiment + '_CNN: Fold %d : f1_macroscore: %.4f' % (f + 1, f1_MacroNet[f]))\n",
    "  print(experiment + '_CNN: Fold %d : f1_weightedscore: %.4f' % (f + 1, f1_weightedNet[f]))\n",
    "  print(experiment + '_CNN: Fold %d : acc: %.4f' % (f + 1, accNet[f]))\n",
    "  f += 1\n",
    "\n",
    "conf_mat /= conf_mat.sum(axis=1, keepdims = True)\n",
    "ax = sns.heatmap(conf_mat, cmap='YlGnBu', annot = True, fmt='.4f', vmin=0, vmax=1, annot_kws = {'fontsize':12})\n",
    "#ax.set_yticklabels(['NC', 'PD'], rotation = 0) # for CSP and IIR\n",
    "#ax.set_yticklabels(['PD', 'NC'], rotation = 0) # for spectral\n",
    "ax.set_yticklabels(['LA', 'HA'], rotation = 0)\n",
    "#ax.set_yticklabels(['Sad', 'Happy', 'Fear', 'Disgust', 'Surprise', 'Anger'], rotation = 0)\n",
    "#ax.set_xticklabels(['Sad', 'Happy', 'Fear', 'Disgust', 'Surprise', 'Anger'], rotation = 0)\n",
    "ax.set_xticklabels(['LA', 'HA'], rotation = 0)\n",
    "#ax.set_xticklabels(['NC', 'PD'], rotation = 0) # for CSP and IIR\n",
    "#ax.set_xticklabels(['PD', 'NC'], rotation = 0) # for spectral\n",
    "\n",
    "ax.set_title(plot_title)\n",
    "ax.get_figure().savefig(filename[:-4]+'_conf_mat'+'.png')\n",
    "plt.show()\n",
    "\n",
    "print('Mean and std of F1 MACRO is %.4f +- %.4f' % (np.mean(f1_MacroNet), np.std(f1_MacroNet)))\n",
    "print('Mean and std of F1 WEIGHTED is %.4f +- %.4f' % (np.mean(f1_weightedNet), np.std(f1_weightedNet)))\n",
    "print('Mean and std of accuracy is %.4f +- %.4f' % (np.mean(accNet), np.std(accNet)))\n",
    "\n",
    "# Save results\n",
    "sio.savemat(filename, {'precisionNet': precisionNet,'recallNet': recallNet, 'f1_MacroNet': f1_MacroNet,\n",
    "                       'f1_weightedNet':f1_weightedNet,'accNet':accNet, 'conf_mat':conf_mat,\n",
    "                      'best_params':best_params, 'experiment':experiment,'nb_filters':nb_filters,\n",
    "                       'kernel_size':kernel_size, 'pool_size':pool_size, 'stride_size':stride_size,'padding':padding,\n",
    "                       'weight_decay':weight_decay, 'dense_layer_neuron_num':dense_layer_neuron_num,'epochs':epochs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
